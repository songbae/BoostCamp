{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_masked_multi_head_attention.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9KsBGZpKkWki"},"source":["##**8. Masked Multi-head Attention**\r\n","1. Masked Multi-head Attention 구현.\r\n","2. Encoder-Decoder Attention 구현."]},{"cell_type":"markdown","metadata":{"id":"8qRU5DFY2OM8"},"source":["### **필요 패키지 import**"]},{"cell_type":"code","metadata":{"id":"lDtMioSQQ1bB","executionInfo":{"status":"ok","timestamp":1612713795787,"user_tz":-540,"elapsed":3285,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["from torch import nn\r\n","from torch.nn import functional as F\r\n","from tqdm import tqdm\r\n","\r\n","import torch\r\n","import math"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QBiZObgRep_Q"},"source":["### **데이터 전처리**"]},{"cell_type":"markdown","metadata":{"id":"pfTSaGYteuze"},"source":["데이터의 값과 형태를 좀 더 명확하게 보기 위해 sample을 줄이겠습니다."]},{"cell_type":"code","metadata":{"id":"e9ULZIqTenSc","executionInfo":{"status":"ok","timestamp":1612713799365,"user_tz":-540,"elapsed":593,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["pad_id = 0\r\n","vocab_size = 100\r\n","\r\n","data = [\r\n","  [62, 13, 47, 39, 78, 33, 56, 13],\r\n","  [60, 96, 51, 32, 90],\r\n","  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21],\r\n","  [66, 88, 98, 47],\r\n","  [77, 65, 51, 77, 19, 15, 35, 19, 23]\r\n","]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Hx3mcivgMyH","executionInfo":{"status":"ok","timestamp":1612713799673,"user_tz":-540,"elapsed":459,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["def padding(data):\r\n","  max_len = len(max(data, key=len))\r\n","  print(f\"Maximum sequence length: {max_len}\")\r\n","\r\n","  for i, seq in enumerate(tqdm(data)):\r\n","    if len(seq) < max_len:\r\n","      data[i] = seq + [pad_id] * (max_len - len(seq))\r\n","\r\n","  return data, max_len"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3e8FiNvgX60","executionInfo":{"status":"ok","timestamp":1612713800224,"user_tz":-540,"elapsed":591,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"624bb622-8e7a-4353-9d76-ed70dc2259e7","colab":{"base_uri":"https://localhost:8080/"}},"source":["data, max_len = padding(data)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["100%|██████████| 5/5 [00:00<00:00, 4327.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["Maximum sequence length: 10\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hwPSIWYugaN0","executionInfo":{"status":"ok","timestamp":1612713800499,"user_tz":-540,"elapsed":477,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"a31c386e-bd4c-4296-8944-a25820662bef","colab":{"base_uri":"https://localhost:8080/"}},"source":["data"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[62, 13, 47, 39, 78, 33, 56, 13, 0, 0],\n"," [60, 96, 51, 32, 90, 0, 0, 0, 0, 0],\n"," [35, 45, 48, 65, 91, 99, 92, 10, 3, 21],\n"," [66, 88, 98, 47, 0, 0, 0, 0, 0, 0],\n"," [77, 65, 51, 77, 19, 15, 35, 19, 23, 0]]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"rwqjACx8iidc"},"source":["### **Hyperparameter 세팅 및 embedding**"]},{"cell_type":"code","metadata":{"id":"p-Ngp2nWimS8","executionInfo":{"status":"ok","timestamp":1612713801663,"user_tz":-540,"elapsed":581,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["d_model = 8  # model의 hidden size\r\n","num_heads = 2  # head의 개수\r\n","inf = 1e12"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJMi2Xsni5uq","executionInfo":{"status":"ok","timestamp":1612713802492,"user_tz":-540,"elapsed":555,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["embedding = nn.Embedding(vocab_size, d_model)\r\n","\r\n","# B: batch size, L: maximum sequence length\r\n","batch = torch.LongTensor(data)  # (B, L)\r\n","batch_emb = embedding(batch)  # (B, L, d_model)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tLCUQwojcUb","executionInfo":{"status":"ok","timestamp":1612713803233,"user_tz":-540,"elapsed":605,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"ca253d99-a727-440c-ebb9-468e39bc846b","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(batch_emb)\r\n","print(batch_emb.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[[-1.1328,  1.1836, -0.8218, -0.1144,  0.1858,  0.2780,  1.4985,\n","          -0.0320],\n","         [-1.8819, -0.4833, -1.4177,  0.3122,  0.5106, -0.3963,  0.1472,\n","          -0.3934],\n","         [-1.4994,  0.8036,  0.9598,  0.5163,  0.7783, -1.4470,  0.2666,\n","          -0.4309],\n","         [ 1.4867, -0.6075,  0.6077,  0.8513, -0.0258,  0.3367, -0.7096,\n","           1.5355],\n","         [ 0.2289,  2.6304, -0.4596, -1.0269,  0.0682,  1.6041, -0.3886,\n","          -0.5839],\n","         [ 0.6725, -0.6069, -1.1035, -0.0139, -0.6283,  0.0087, -0.5937,\n","          -2.2951],\n","         [ 1.1041,  1.4193,  0.1000, -1.1793,  1.3306,  0.6451, -1.1280,\n","           2.2734],\n","         [-1.8819, -0.4833, -1.4177,  0.3122,  0.5106, -0.3963,  0.1472,\n","          -0.3934],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460]],\n","\n","        [[-0.5723,  0.5915,  0.8100, -1.6074, -0.9518,  0.1475, -1.6895,\n","          -1.3010],\n","         [ 0.8867, -2.2586,  0.5407, -0.8918, -1.1468, -1.4038,  0.6957,\n","           0.8184],\n","         [-0.8477,  0.7635, -0.3272, -2.1345,  1.0417, -0.1122,  0.4185,\n","           0.3511],\n","         [-1.8399,  0.1493, -0.6445,  0.8879, -1.7139, -0.4212,  2.6152,\n","          -1.1219],\n","         [-0.6034,  0.8577, -2.4643, -1.7204,  0.3035, -0.3493,  0.7747,\n","          -1.6315],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460]],\n","\n","        [[-0.7404,  2.0545,  2.1475, -0.2049, -1.9844,  0.6217, -0.1826,\n","           0.4871],\n","         [-0.4702,  1.7867,  0.8326,  0.1552,  0.0986, -0.4726, -0.2424,\n","           0.4954],\n","         [-0.8812,  0.6632,  0.4682,  0.5971,  0.0137, -0.4221,  0.9222,\n","          -1.3802],\n","         [-1.1680, -0.3435, -2.1650,  0.6590, -0.3584, -1.3275,  0.9571,\n","          -0.7995],\n","         [ 1.8614, -0.7780, -0.0635, -0.5881, -0.9441, -0.4161,  1.7208,\n","           1.2303],\n","         [ 0.6657,  0.8502, -0.6789, -1.9553, -1.4590, -2.2148,  1.8821,\n","           0.3191],\n","         [ 0.0348, -0.4782, -0.5922, -0.2496, -0.2964,  1.3984,  1.2924,\n","           0.5355],\n","         [-0.1808,  0.3880,  1.6388,  0.6379, -1.2646,  0.5453,  0.1874,\n","           0.9033],\n","         [ 0.3104,  0.3189, -1.0346, -0.3917, -0.1234, -0.5912,  0.0363,\n","          -0.7211],\n","         [-0.1615, -0.8436, -1.3531, -0.7659,  0.5755, -0.1638,  2.0885,\n","           1.7100]],\n","\n","        [[ 1.0895,  0.1241, -0.7851,  0.3316, -0.3850,  0.6924,  0.5393,\n","          -1.3453],\n","         [-0.0421, -0.2633, -0.5223, -0.2731,  0.1121,  0.4999, -0.7768,\n","          -0.0051],\n","         [ 0.2775,  0.5029, -0.1370, -0.5794,  0.9392, -0.6926,  0.4582,\n","           0.6746],\n","         [-1.4994,  0.8036,  0.9598,  0.5163,  0.7783, -1.4470,  0.2666,\n","          -0.4309],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460]],\n","\n","        [[ 0.3528, -0.1526, -0.9128, -0.1690, -0.9052,  1.0969,  0.1373,\n","           0.0103],\n","         [-1.1680, -0.3435, -2.1650,  0.6590, -0.3584, -1.3275,  0.9571,\n","          -0.7995],\n","         [-0.8477,  0.7635, -0.3272, -2.1345,  1.0417, -0.1122,  0.4185,\n","           0.3511],\n","         [ 0.3528, -0.1526, -0.9128, -0.1690, -0.9052,  1.0969,  0.1373,\n","           0.0103],\n","         [-0.9854,  0.4269, -0.3397,  0.5372,  0.3367,  0.2395,  0.1425,\n","          -1.0880],\n","         [ 0.1694,  0.5451, -0.2673,  0.6563, -0.0408, -0.2438,  1.7897,\n","           1.2801],\n","         [-0.7404,  2.0545,  2.1475, -0.2049, -1.9844,  0.6217, -0.1826,\n","           0.4871],\n","         [-0.9854,  0.4269, -0.3397,  0.5372,  0.3367,  0.2395,  0.1425,\n","          -1.0880],\n","         [ 0.6705, -0.9591,  1.6070, -0.6841, -0.3216, -0.8601, -1.1196,\n","          -0.2378],\n","         [ 0.7999,  0.5157,  0.2910,  0.9721,  0.5231, -1.2296,  0.7328,\n","          -1.3460]]], grad_fn=<EmbeddingBackward>)\n","torch.Size([5, 10, 8])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dO3gxeyhpyF2"},"source":["### **Mask 구축**"]},{"cell_type":"markdown","metadata":{"id":"0NDEQF64p5pN"},"source":["`True`는 attention이 적용될 부분, `False`는 masking될 자리입니다."]},{"cell_type":"code","metadata":{"id":"aB0A4elupM2g","executionInfo":{"status":"ok","timestamp":1612713811744,"user_tz":-540,"elapsed":573,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"69325f99-106f-444f-fd6c-a95412a55ebb","colab":{"base_uri":"https://localhost:8080/"}},"source":["padding_mask = (batch != pad_id).unsqueeze(1)  # (B, 1, L)\r\n","\r\n","print(padding_mask)\r\n","print(padding_mask.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[[ True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n","\n","        [[ True,  True,  True,  True,  True, False, False, False, False, False]],\n","\n","        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n","\n","        [[ True,  True,  True,  True, False, False, False, False, False, False]],\n","\n","        [[ True,  True,  True,  True,  True,  True,  True,  True,  True, False]]])\n","torch.Size([5, 1, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"88cD54evrEo6","executionInfo":{"status":"ok","timestamp":1612713812065,"user_tz":-540,"elapsed":391,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"add7f80f-bc1f-4cff-b95d-22972d5a4b55","colab":{"base_uri":"https://localhost:8080/"}},"source":["nopeak_mask = torch.ones([1, max_len, max_len], dtype=torch.bool)  # (1, L, L)\r\n","nopeak_mask = torch.tril(nopeak_mask)  # (1, L, L)\r\n","\r\n","print(nopeak_mask)\r\n","print(nopeak_mask.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([[[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n","torch.Size([1, 10, 10])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FMzB8_jarycy","executionInfo":{"status":"ok","timestamp":1612713813933,"user_tz":-540,"elapsed":580,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"03c905e2-1dc8-4fa3-b1b6-cc3a9061e0c5","colab":{"base_uri":"https://localhost:8080/"}},"source":["mask = padding_mask & nopeak_mask  # (B, L, L)\r\n","\r\n","print(mask)\r\n","print(mask.shape)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([[[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n","\n","        [[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False]],\n","\n","        [[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n","\n","        [[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False]],\n","\n","        [[ True, False, False, False, False, False, False, False, False, False],\n","         [ True,  True, False, False, False, False, False, False, False, False],\n","         [ True,  True,  True, False, False, False, False, False, False, False],\n","         [ True,  True,  True,  True, False, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True, False, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n","         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False]]])\n","torch.Size([5, 10, 10])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"urXMBRnRgqvw"},"source":["### **Linear transformation & 여러 head로 나누기**"]},{"cell_type":"code","metadata":{"id":"9DWKDqgCgfMk","executionInfo":{"status":"ok","timestamp":1612713817867,"user_tz":-540,"elapsed":595,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}}},"source":["w_q = nn.Linear(d_model, d_model)\r\n","w_k = nn.Linear(d_model, d_model)\r\n","w_v = nn.Linear(d_model, d_model)\r\n","\r\n","w_0 = nn.Linear(d_model, d_model)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-vSL7PwnV6k","executionInfo":{"status":"ok","timestamp":1612713818109,"user_tz":-540,"elapsed":576,"user":{"displayName":"Yk","photoUrl":"","userId":"14513703065884681238"}},"outputId":"c0539e6c-2f07-49ec-cb59-227298453d77","colab":{"base_uri":"https://localhost:8080/"}},"source":["q = w_q(batch_emb)  # (B, L, d_model)\r\n","k = w_k(batch_emb)  # (B, L, d_model)\r\n","v = w_v(batch_emb)  # (B, L, d_model)\r\n","\r\n","batch_size = q.shape[0]\r\n","d_k = d_model // num_heads\r\n","\r\n","q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","\r\n","q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","\r\n","print(q.shape)\r\n","print(k.shape)\r\n","print(v.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["torch.Size([5, 2, 10, 4])\n","torch.Size([5, 2, 10, 4])\n","torch.Size([5, 2, 10, 4])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NWrDA5_Sofad"},"source":["### **Masking이 적용된 self-attention 구현**"]},{"cell_type":"code","metadata":{"id":"GqaQmVQdvMZB"},"source":["attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adlRCt6mvMy5"},"source":["masks = mask.unsqueeze(1)  # (B, 1, L, L)\r\n","masked_attn_scores = attn_scores.masked_fill_(masks == False, -1 * inf)  # (B, num_heads, L, L)\r\n","\r\n","print(masked_attn_scores)\r\n","print(masked_attn_scores.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9EqMuVJFwHhI"},"source":["`-1* inf`로 masking된 부분은 softmax 후 0이 됩니다."]},{"cell_type":"code","metadata":{"id":"jVNze4elv4Uf"},"source":["attn_dists = F.softmax(masked_attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n","\r\n","print(attn_dists)\r\n","print(attn_dists.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBwm34bswV7e"},"source":["attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n","\r\n","print(attn_values.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2Xab7WKzTEU"},"source":["### **전체 코드**"]},{"cell_type":"code","metadata":{"id":"LlF7R6DIzVWc"},"source":["class MultiheadAttention(nn.Module):\r\n","  def __init__(self):\r\n","    super(MultiheadAttention, self).__init__()\r\n","\r\n","    # Q, K, V learnable matrices\r\n","    self.w_q = nn.Linear(d_model, d_model)\r\n","    self.w_k = nn.Linear(d_model, d_model)\r\n","    self.w_v = nn.Linear(d_model, d_model)\r\n","\r\n","    # Linear transformation for concatenated outputs\r\n","    self.w_0 = nn.Linear(d_model, d_model)\r\n","\r\n","  def forward(self, q, k, v, mask=None):\r\n","    batch_size = q.shape[0]\r\n","\r\n","    q = self.w_q(q)  # (B, L, d_model)\r\n","    k = self.w_k(k)  # (B, L, d_model)\r\n","    v = self.w_v(v)  # (B, L, d_model)\r\n","\r\n","    q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","    k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","    v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n","\r\n","    q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","    k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","    v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n","\r\n","    attn_values = self.self_attention(q, k, v, mask=mask)  # (B, num_heads, L, d_k)\r\n","    attn_values = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, d_model)  # (B, L, num_heads, d_k) => (B, L, d_model)\r\n","\r\n","    return self.w_0(attn_values)\r\n","\r\n","  def self_attention(self, q, k, v, mask=None):\r\n","    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\r\n","\r\n","    if mask is not None:\r\n","      mask = mask.unsqueeze(1)  # (B, 1, L, L) or  (B, 1, 1, L)\r\n","      attn_scores = attn_scores.masked_fill_(mask == False, -1*inf)\r\n","\r\n","    attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n","\r\n","    attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n","\r\n","    return attn_values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jYLuu_9alQxT"},"source":["multihead_attn = MultiheadAttention()\r\n","\r\n","outputs = multihead_attn(batch_emb, batch_emb, batch_emb, mask=mask)  # (B, L, d_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMiXlYjSlTfB"},"source":["print(outputs)\r\n","print(outputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1g99JEEFwFv"},"source":["### **Encoder-Decoder attention**"]},{"cell_type":"markdown","metadata":{"id":"o2PRoF4fF4ah"},"source":["Query, key, value만 달라질 뿐 구현은 동일합니다.  \r\n","Decoder에 들어갈 batch만 별도 구현하겠습니다."]},{"cell_type":"code","metadata":{"id":"p26ra2BsGEdb"},"source":["trg_data = [\r\n","  [33, 11, 49, 10],\r\n","  [88, 34, 5, 29, 99, 45, 11, 25],\r\n","  [67, 25, 15, 90, 54, 4, 92, 10, 46, 20, 88 ,19],\r\n","  [16, 58, 91, 47, 12, 5, 8],\r\n","  [71, 63, 62, 7, 9, 11, 55, 91, 32, 48]\r\n","]\r\n","\r\n","trg_data, trg_max_len = padding(trg_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYysB4EKHKGI"},"source":["# S_L: source maximum sequence length, T_L: target maximum sequence length\r\n","src_batch = batch  # (B, S_L)\r\n","trg_batch = torch.LongTensor(trg_data)  # (B, T_L)\r\n","\r\n","print(src_batch.shape)\r\n","print(trg_batch.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AieDxWYIHXKc"},"source":["src_emb = embedding(src_batch)  # (B, S_L, d_w)\r\n","trg_emb = embedding(trg_batch)  # (B, T_L, d_w)\r\n","\r\n","print(src_emb.shape)\r\n","print(trg_emb.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zxCjmPurH2b7"},"source":["`src_emb`를 encoder에서 나온 결과, 그리고 `trg_emb`를 masked multi-head attention 후 결과로 가정합니다."]},{"cell_type":"code","metadata":{"id":"AUhY-z8JHeUE"},"source":["q = w_q(trg_emb)  # (B, T_L, d_model)\r\n","k = w_k(src_emb)  # (B, S_L, d_model)\r\n","v = w_v(src_emb)  # (B, S_L, d_model)\r\n","\r\n","batch_size = q.shape[0]\r\n","d_k = d_model // num_heads\r\n","\r\n","q = q.view(batch_size, -1, num_heads, d_k)  # (B, T_L, num_heads, d_k)\r\n","k = k.view(batch_size, -1, num_heads, d_k)  # (B, S_L, num_heads, d_k)\r\n","v = v.view(batch_size, -1, num_heads, d_k)  # (B, S_L, num_heads, d_k)\r\n","\r\n","q = q.transpose(1, 2)  # (B, num_heads, T_L, d_k)\r\n","k = k.transpose(1, 2)  # (B, num_heads, S_L, d_k)\r\n","v = v.transpose(1, 2)  # (B, num_heads, S_L, d_k)\r\n","\r\n","print(q.shape)\r\n","print(k.shape)\r\n","print(v.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeqjkVqkIdxO"},"source":["attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, T_L, S_L)\r\n","attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, T_L, S_L)\r\n","\r\n","print(attn_dists.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VQv4IINbItS0"},"source":["attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, T_L, d_k)\r\n","\r\n","print(attn_values.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RLCHeCbtJDy9"},"source":["Masked multi-head attention 후 나온 결과와 동일한 shape를 가지며 이후 layer에서 전체 연산도 동일하게 진행됩니다."]}]}