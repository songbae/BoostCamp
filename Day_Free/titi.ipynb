{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a955008dc820c70e8c41cf6f115bde945f96d07d69c96eec2ee76e53bea50083"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   PassengerId  Pclass                                          Name     Sex  ...   Ticket     Fare  Cabin Embarked\n0          892       3                              Kelly, Mr. James    male  ...   330911   7.8292    NaN        Q\n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female  ...   363272   7.0000    NaN        S\n2          894       2                     Myles, Mr. Thomas Francis    male  ...   240276   9.6875    NaN        Q\n3          895       3                              Wirz, Mr. Albert    male  ...   315154   8.6625    NaN        S\n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  ...  3101298  12.2875    NaN        S\n\n[5 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter \n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train=pd.read_csv('./data/train.csv')\n",
    "df_test=pd.read_csv('./data/test.csv')\n",
    "df_sub=pd.read_csv('./data/gender_submission.csv')\n",
    "df_train.head()\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   male\n0     1\n1     0\n2     0\n3     0\n4     1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass\n",
       "0            1         0       3\n",
       "1            2         1       1\n",
       "2            3         1       3\n",
       "3            4         1       1\n",
       "4            5         0       3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "sex=pd.get_dummies(df_train['Sex'],drop_first=True)\n",
    "sex1=pd.get_dummies(df_test['Sex'],drop_first=True)\n",
    "print(sex.head())\n",
    "df_train.drop(['Name','Sex','Parch','Ticket','SibSp','Fare','Cabin','Age','Embarked'],axis=1,inplace=True)\n",
    "df_test.drop(['Name','Sex','Parch','Ticket','SibSp','Fare','Cabin','Age','Embarked'],axis=1,inplace=True)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  male\n",
       "0            1         0       3     1\n",
       "1            2         1       1     0\n",
       "2            3         1       3     0\n",
       "3            4         1       1     0\n",
       "4            5         0       3     1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "df_train=pd.concat([df_train,sex],axis=1)\n",
    "df_test=pd.concat([df_test,sex1],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            0         1         2         3\n0   -1.730108 -0.789272  0.827377  0.737695\n1   -1.726220  1.266990 -1.566107 -1.355574\n2   -1.722332  1.266990  0.827377 -1.355574\n3   -1.718444  1.266990 -1.566107 -1.355574\n4   -1.714556 -0.789272  0.827377  0.737695\n..        ...       ...       ...       ...\n886  1.714556 -0.789272 -0.369365  0.737695\n887  1.718444  1.266990 -1.566107 -1.355574\n888  1.722332 -0.789272  0.827377 -1.355574\n889  1.726220  1.266990 -1.566107  0.737695\n890  1.730108 -0.789272  0.827377  0.737695\n\n[891 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "scaler1,scaler2=StandardScaler(),StandardScaler()\n",
    "train_columns=df_train.columns\n",
    "test_columns=df_test.columns\n",
    "\n",
    "df_train=pd.DataFrame(scaler1.fit_transform(df_train))\n",
    "df_test=pd.DataFrame(scaler2.fit_transform(df_test))\n",
    "\n",
    "print(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns=train_columns\n",
    "df_test.columns=test_columns\n",
    "features=df_train.iloc[:,2:].columns.tolist()\n",
    "target=df_train.loc[:,'Survived'].name\n",
    "\n",
    "X_train=df_train.iloc[:,2:].values\n",
    "y_train=df_train.loc[:,'Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n  (fc1): Linear(in_features=2, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=512, bias=True)\n  (fc3): Linear(in_features=512, out_features=2, bias=True)\n  (dropout): Dropout(p=0.01, inplace=False)\n  (layer): Sequential(\n    (0): Linear(in_features=2, out_features=512, bias=True)\n    (1): Dropout(p=0.01, inplace=False)\n    (2): Linear(in_features=512, out_features=512, bias=True)\n    (3): Dropout(p=0.01, inplace=False)\n    (4): Linear(in_features=512, out_features=2, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1=nn.Linear(2,512)\n",
    "        self.fc2=nn.Linear(512,512)\n",
    "        self.fc3=nn.Linear(512,2)\n",
    "        self.dropout=nn.Dropout(0.01)\n",
    "\n",
    "        self.layer=nn.Sequential(\n",
    "            self.fc1,\n",
    "            self.dropout,\n",
    "            self.fc2,\n",
    "            self.dropout,\n",
    "            self.fc3\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        for idx,i in enumerate(self.layer):\n",
    "            x=i(x)\n",
    "            if idx==1 or idx==3:\n",
    "                x=F.relu(x)\n",
    "        return x\n",
    "model=Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.1094, 0.1003, 0.1362, 0.0942, 0.0967, 0.0890, 0.0752, 0.0717, 0.1393,\n",
      "        0.1412, 0.1256, 0.1208, 0.1048, 0.1130, 0.1254, 0.1154, 0.1008, 0.0354,\n",
      "        0.1217, 0.0980, 0.0372, 0.0129, 0.1182, 0.0673, 0.1576, 0.1082, 0.0849,\n",
      "        0.0718, 0.1154, 0.1048, 0.0986, 0.1373, 0.1280, 0.0050, 0.0883, 0.0843,\n",
      "        0.1088, 0.1057, 0.0805, 0.1331, 0.1103, 0.1004, 0.0861, 0.1178, 0.1457,\n",
      "        0.0901, 0.0790, 0.1479, 0.0717, 0.1363, 0.0724, 0.0973, 0.0953, 0.1438,\n",
      "        0.0512, 0.0961, 0.1282, 0.0954, 0.1113, 0.0970, 0.0785, 0.1426, 0.0398,\n",
      "        0.0960], grad_fn=<MaxBackward0>)\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "validation loss decreased:\tinf->0.4714053204297752\n",
      "Epoch:1\t Train_loss:0.4714053204297752\t Train Accuracy:0.0\n",
      "validation loss decreased:\t0.4714053204297752->0.45913085370783585\n",
      "validation loss decreased:\t0.45913085370783585->0.42793780796087155\n",
      "validation loss decreased:\t0.42793780796087155->0.42781528938362534\n",
      "validation loss decreased:\t0.42781528938362534->0.4271738480621166\n",
      "validation loss decreased:\t0.4271738480621166->0.426700853866608\n",
      "validation loss decreased:\t0.426700853866608->0.42616471326536004\n",
      "validation loss decreased:\t0.42616471326536004->0.42594861594131467\n",
      "validation loss decreased:\t0.42594861594131467->0.42588937060918836\n",
      "tensor([0.9660, 1.6982, 0.0574, 1.6872, 0.9710, 0.9647, 0.3285, 0.9645, 0.0462,\n",
      "        1.3271, 0.0470, 1.7228, 0.9742, 0.9147, 0.0449, 1.3017, 0.9112, 0.8760,\n",
      "        0.0697, 0.0431, 0.8617, 0.8408, 0.0550, 0.2902, 0.0420, 0.0698, 0.9757,\n",
      "        0.3038, 0.0477, 0.9419, 0.3264, 1.6333, 0.0901, 0.8290, 0.3209, 0.2996,\n",
      "        0.9302, 0.9748, 0.0416, 0.0518, 0.0770, 1.3184, 0.9750, 1.2994, 0.1011,\n",
      "        0.9687, 0.9791, 0.0753, 0.9661, 0.0401, 0.8878, 0.9677, 1.7082, 1.2643,\n",
      "        0.3181, 0.3000, 1.2993, 0.9626, 1.2398, 0.9318, 0.9613, 1.7033, 0.3365,\n",
      "        0.9131], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:101\t Train_loss:0.4270668703347471\t Train Accuracy:0.0\n",
      "validation loss decreased:\t0.42588937060918836->0.4258589981315905\n",
      "validation loss decreased:\t0.4258589981315905->0.42571911119106726\n",
      "validation loss decreased:\t0.42571911119106726->0.4255644964091761\n",
      "validation loss decreased:\t0.4255644964091761->0.4253325411891029\n",
      "validation loss decreased:\t0.4253325411891029->0.4250659075480802\n",
      "validation loss decreased:\t0.4250659075480802->0.4250607638519761\n",
      "tensor([0.9069, 1.5906, 0.0484, 1.6500, 0.9488, 0.9571, 0.3088, 0.9516, 0.0685,\n",
      "        1.2826, 0.1220, 1.6288, 0.9470, 0.9446, 0.0794, 1.1365, 0.9209, 0.8165,\n",
      "        0.0543, 0.0484, 0.8167, 0.8392, 0.0885, 0.3062, 0.0960, 0.0582, 0.9353,\n",
      "        0.3047, 0.0537, 0.9481, 0.2908, 1.6311, 0.0216, 0.8372, 0.3106, 0.2986,\n",
      "        0.9496, 0.9460, 0.0656, 0.0524, 0.0482, 1.2579, 0.9511, 1.2488, 0.0607,\n",
      "        0.9375, 0.9398, 0.0466, 0.9571, 0.0577, 0.9451, 0.9587, 1.6357, 1.3064,\n",
      "        0.2805, 0.2866, 1.2404, 0.9452, 1.2916, 0.9332, 0.9409, 1.5635, 0.3096,\n",
      "        0.9639], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:201\t Train_loss:0.42613901560582945\t Train Accuracy:0.0\n",
      "validation loss decreased:\t0.4250607638519761->0.42470210712955675\n",
      "validation loss decreased:\t0.42470210712955675->0.4237490406245114\n",
      "tensor([0.9233, 1.5285, 0.0550, 1.5817, 0.8039, 0.9366, 0.2707, 0.9180, 0.0464,\n",
      "        1.2485, 0.0515, 1.5636, 0.9362, 0.8949, 0.0397, 1.2544, 0.9392, 0.8125,\n",
      "        0.0380, 0.0541, 0.6585, 0.8351, 0.0420, 0.2849, 0.0402, 0.0413, 0.9093,\n",
      "        0.2935, 0.0731, 0.9153, 0.2866, 1.5570, 0.0584, 0.7656, 0.2958, 0.2677,\n",
      "        0.9341, 0.9261, 0.1103, 0.0355, 0.0352, 1.2506, 0.9359, 1.2371, 0.0384,\n",
      "        0.9018, 0.9229, 0.0467, 0.9262, 0.0546, 0.9368, 0.9443, 1.5241, 1.2322,\n",
      "        0.2905, 0.2880, 1.1990, 0.9228, 1.2504, 0.9176, 0.9368, 1.5518, 0.2917,\n",
      "        0.9159], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:301\t Train_loss:0.42625704129703\t Train Accuracy:0.0\n",
      "tensor([1.0098, 1.5070, 0.0581, 1.5134, 0.9856, 1.0169, 0.3480, 0.9957, 0.0607,\n",
      "        1.1954, 0.0561, 1.5214, 1.0070, 1.0097, 0.0561, 1.2018, 1.0165, 0.8598,\n",
      "        0.0538, 0.0615, 0.8683, 0.7661, 0.0550, 0.3488, 0.0573, 0.0554, 1.0165,\n",
      "        0.2907, 0.0825, 1.0086, 0.3601, 1.4986, 0.0537, 0.8610, 0.3505, 0.3445,\n",
      "        1.0032, 0.9654, 0.0755, 0.0978, 0.0656, 1.1796, 1.0168, 1.2104, 0.0670,\n",
      "        1.0098, 0.9918, 0.0624, 1.0176, 0.0436, 1.0043, 1.0169, 1.4786, 1.0895,\n",
      "        0.3534, 0.3588, 1.1953, 0.9458, 1.1993, 1.0160, 0.8999, 1.5070, 0.3649,\n",
      "        0.9895], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:401\t Train_loss:0.42494116414893784\t Train Accuracy:0.0\n",
      "tensor([1.0245, 1.3785, 0.0153, 1.4661, 1.0364, 1.0394, 0.3284, 0.9031, 0.0178,\n",
      "        1.1481, 0.0029, 1.5341, 1.0290, 1.0552, 0.0115, 1.1115, 1.0128, 0.8506,\n",
      "        0.0078, 0.0253, 0.8028, 0.8655, 0.0065, 0.3249, 0.0140, 0.0117, 1.0396,\n",
      "        0.3310, 0.0263, 1.0415, 0.3291, 1.5310, 0.0071, 0.8523, 0.3263, 0.2651,\n",
      "        1.0297, 1.0423, 0.0437, 0.0101, 0.0175, 0.9694, 1.0302, 1.1388, 0.0093,\n",
      "        1.0309, 0.8645, 0.0386, 1.0239, 0.0114, 1.0198, 1.0290, 1.5285, 1.1343,\n",
      "        0.3388, 0.3266, 1.1480, 1.0346, 1.1324, 1.0424, 1.0193, 1.5170, 0.3328,\n",
      "        1.0373], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:501\t Train_loss:0.4252187557966282\t Train Accuracy:0.0\n",
      "validation loss decreased:\t0.4237490406245114->0.42316271579404946\n",
      "tensor([1.0780, 1.5565, 0.0361, 1.5508, 1.1078, 1.0938, 0.3326, 1.0939, 0.0358,\n",
      "        1.1756, 0.0465, 1.4993, 1.0853, 1.0939, 0.0342, 1.1270, 1.0832, 0.9051,\n",
      "        0.0278, 0.0347, 0.9161, 0.8219, 0.0352, 0.3505, 0.0395, 0.0366, 1.0947,\n",
      "        0.3495, 0.0358, 1.0939, 0.3713, 1.5144, 0.0366, 0.9125, 0.3523, 0.3583,\n",
      "        1.0861, 1.0841, 0.0345, 0.0430, 0.0366, 1.1641, 1.0853, 1.1449, 0.0342,\n",
      "        1.0905, 1.0309, 0.0479, 1.0689, 0.0324, 1.0939, 1.0837, 1.5389, 1.1750,\n",
      "        0.3571, 0.3523, 1.1682, 1.0869, 1.1633, 1.0941, 1.0868, 1.5285, 0.3566,\n",
      "        0.9650], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:601\t Train_loss:0.4256151251337099\t Train Accuracy:0.0\n",
      "tensor([1.1074, 1.6027, 0.0490, 1.4330, 1.0527, 1.1074, 0.3534, 1.1024, 0.0546,\n",
      "        1.2074, 0.0611, 1.5915, 1.1051, 1.0854, 0.0422, 1.1920, 1.1061, 0.9246,\n",
      "        0.0468, 0.0468, 0.9414, 0.9303, 0.0576, 0.3687, 0.0495, 0.0432, 1.1067,\n",
      "        0.3607, 0.0659, 1.1060, 0.3673, 1.5796, 0.0523, 0.7652, 0.3629, 0.3668,\n",
      "        1.0886, 1.0826, 0.0714, 0.0407, 0.0555, 1.2155, 1.1009, 1.1664, 0.0503,\n",
      "        1.1020, 1.0867, 0.0659, 1.1051, 0.0369, 1.1064, 1.0912, 1.5475, 1.2026,\n",
      "        0.3636, 0.3695, 1.2023, 1.0821, 1.2137, 1.0110, 1.0702, 1.5945, 0.3560,\n",
      "        1.0972], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:701\t Train_loss:0.4257766381313395\t Train Accuracy:0.0\n",
      "tensor([1.1209, 1.5876, 0.0592, 1.6327, 1.1115, 1.1285, 0.3499, 1.1039, 0.0664,\n",
      "        1.2476, 0.0665, 1.6250, 1.1268, 1.1106, 0.0610, 1.1125, 1.1215, 0.9741,\n",
      "        0.0611, 0.0707, 0.9772, 0.9839, 0.0713, 0.3483, 0.0518, 0.0678, 1.1186,\n",
      "        0.3409, 0.0614, 1.1165, 0.3492, 1.6395, 0.0703, 0.9712, 0.3403, 0.3236,\n",
      "        1.1247, 1.1101, 0.0614, 0.0595, 0.0622, 1.2381, 1.1153, 1.2349, 0.0546,\n",
      "        1.1148, 1.0931, 0.0697, 1.0909, 0.0703, 1.1309, 1.1312, 1.6389, 1.2062,\n",
      "        0.3271, 0.3470, 1.2527, 1.1075, 1.1838, 1.1292, 1.1303, 1.6073, 0.3461,\n",
      "        1.1094], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:801\t Train_loss:0.4255402909838398\t Train Accuracy:0.0\n",
      "tensor([1.1220, 1.5854, 0.0684, 1.5532, 1.1332, 1.0196, 0.3551, 1.1288, 0.0599,\n",
      "        1.1855, 0.0540, 1.5523, 1.1340, 1.1267, 0.0631, 1.2335, 1.1254, 0.9836,\n",
      "        0.0476, 0.0535, 0.9908, 0.9901, 0.0602, 0.3599, 0.0540, 0.0525, 1.1112,\n",
      "        0.3493, 0.0546, 1.1304, 0.3560, 1.5954, 0.0606, 0.9963, 0.3556, 0.3641,\n",
      "        1.1241, 1.1389, 0.0548, 0.0558, 0.0495, 1.1972, 1.1252, 1.2253, 0.0518,\n",
      "        1.1382, 1.1344, 0.0595, 1.1389, 0.0571, 1.1038, 1.1394, 1.5828, 1.2135,\n",
      "        0.2806, 0.3537, 1.2263, 1.1195, 1.2256, 1.1324, 1.1383, 1.5835, 0.3518,\n",
      "        1.1317], grad_fn=<MaxBackward0>)\n",
      "tensor([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "Epoch:901\t Train_loss:0.42571151595514345\t Train Accuracy:0.0\n",
      "Train End!!!\n"
     ]
    }
   ],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "batch_size=64\n",
    "n_epochs=1000\n",
    "batch_no=len(X_train)//batch_size\n",
    "\n",
    "train_loss=0\n",
    "train_loss_min=np.Inf\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(batch_no):\n",
    "        start=i*batch_size\n",
    "        end=start+batch_size\n",
    "\n",
    "        x_var=Variable(torch.FloatTensor(X_train[start:end]))\n",
    "        y_var=Variable(torch.LongTensor(y_train[start:end]))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output=model(x_var)\n",
    "        loss=criterion(output,y_var)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        values,labels=torch.max(output,1)\n",
    "        if i%63==0 and epoch%100==0:\n",
    "            print(values)\n",
    "            print(labels)\n",
    "        num_right=np.sum(labels.data.numpy()==y_train[start:end])\n",
    "        train_loss+=loss.item()*batch_size\n",
    "    \n",
    "    train_loss=train_loss/len(X_train)\n",
    "    if train_loss<=train_loss_min:\n",
    "        print(f'validation loss decreased:\\t{train_loss_min}->{train_loss}')\n",
    "        torch.save(model.state_dict(),'model.pt')\n",
    "        train_loss_min=train_loss\n",
    "\n",
    "    if epoch%100==0:\n",
    "         print(f\"Epoch:{epoch+1}\\t Train_loss:{train_loss}\\t Train Accuracy:{num_right/len(y_train[start:end])}\")\n",
    "\n",
    "print(\"Train End!!!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029 -1.32287566]\n [-1.50512029 -1.32287566]\n [-0.31581919 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919 -1.32287566]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-0.31581919  0.75592895]\n [-0.31581919 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-0.31581919  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [-0.31581919  0.75592895]\n [-1.50512029 -1.32287566]\n [-1.50512029  0.75592895]\n [-1.50512029  0.75592895]\n [-0.31581919  0.75592895]\n [-0.31581919  0.75592895]\n [-1.50512029  0.75592895]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191 -1.32287566]\n [-1.50512029 -1.32287566]\n [ 0.87348191 -1.32287566]\n [ 0.87348191  0.75592895]\n [-1.50512029 -1.32287566]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]\n [ 0.87348191  0.75592895]]\n"
     ]
    }
   ],
   "source": [
    "###predictions \n",
    "\n",
    "X_test=df_test.iloc[:,1:].values\n",
    "print(X_test)\n",
    "X_test_var=Variable(torch.FloatTensor(X_test),requires_grad=False)\n",
    "with torch.no_grad():\n",
    "    test_result=model(X_test_var)\n",
    "values,labels= torch.max(test_result,1)\n",
    "survived=labels.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': df_sub['PassengerId'], 'Survived': survived})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ]
}