{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOHlezWG75EqnGR5noArI7e"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IdKLc4YaIXow"},"source":["#!pip install torch==1.6.0\n","!pip install transformers==3.3.1\n","!pip install seqeval\n","!pip install fastprogress\n","!pip install attrdict"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnLj4NEYNOyx"},"source":["해당 과제의 코드는 박장원님의 \"https://github.com/monologg/KoELECTRA/tree/master/finetune\" 레포지토리의 코드를 변경하여 만들어졌습니다."]},{"cell_type":"markdown","metadata":{"id":"_fzRvsLRNXhj"},"source":["추신. 좋은 코드 만들어주시고, 코드 사용을 흔쾌히 허락해주신 박장원님께 감사인사 드립니다."]},{"cell_type":"code","metadata":{"id":"SbUPZJvuJd4i"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvhHW1sbJnhc"},"source":["cd /content/drive/MyDrive/Colab\\ Notebooks/WEEK_NLP_day20_assignment"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VXxx9lqUMYOH"},"source":["학습을 시작하기 전에 같이 동봉된 \"preprocessing.ipynb\"를 실행하여 나오는 \"train.tsv\",\"dev.tsv\"를 \"data/custom-ner\"에 넣어줍니다."]},{"cell_type":"code","metadata":{"id":"JoSoMGt3ISc8"},"source":["!python3 run_ner.py --task custom-ner --config_file koelectra-small.json # config/custom-ner 에서 원하는 모델의 config를 변경하고 넣어주세요."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RrNKofm5Jsdl"},"source":["from transformers import ElectraTokenizer, ElectraForTokenClassification  #다른 모델을 쓸 때는 tokenizer(ex.ElectraTokenizer)와 model(ex.ElectraForTokenClassification)를 바꿔주어야 합니다.\n","\n","  \n","tokenizer = ElectraTokenizer.from_pretrained(\"\")  #tokenizer를 바꾸었다면 from_pretrained에 들어가는 부분을 바꿔주어야 합니다. model config에 있는 model 주소를 적어주시면 됩니다. ex. monologg/koelectra-base-v3-discriminator\n","\n","model = ElectraForTokenClassification.from_pretrained(\"checkpoint가 있는 디렉토리 기입\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Up3mkRRS_7a"},"source":["label_list=['DT-B','DT-I','LC-B','LC-I','OG-B','OG-I','PS-B','PS-I','QT-B','QT-I','TI-B','TI-I','O']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUVaNlH6Lwob"},"source":["Kaggle Competition page에서 \"test.txt\"를 다운 받아서 \"data/custom-ner\"에 넣어줍니다."]},{"cell_type":"code","metadata":{"id":"IAgE7tEJ2X9M"},"source":["texts=[]\n","with open(\"data/custom-ner/test.txt\") as f:\n","  for line in f:\n","    texts.append(line.rsplit(\"\\n\")[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nL396TsMqCL"},"source":["import torch\n","from tqdm.auto import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LwcpAaql-b60"},"source":["labels=[]\n","for idx, sequence in tqdm(enumerate(texts)):\n","  tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n","  inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n","  outputs = model(inputs)\n","  predictions = torch.argmax(outputs[0], dim=2)\n","  labels_=[]\n","  for i,j in zip(tokens,predictions[0].tolist()):\n","    if i in ['[CLS]', '[SEP]']:\n","      continue\n","    if \"##\" in i:\n","      continue\n","    labels_.append(label_list[j])\n","  labels.extend(labels_)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lk5aSkwTMsu7"},"source":["\"submission.csv\"를 kaggle competition에 제출합니다."]},{"cell_type":"markdown","metadata":{"id":"cmylkRmjNB65"},"source":["데이터 전처리,모델 config 튜닝을 이용하여 더 좋은 성적을 얻어보세요."]},{"cell_type":"code","metadata":{"id":"Zt6WuSK_h75C"},"source":["with open(\"submission.csv\",\"w\") as f:\n","  f.write(\"id,tag\\n\")\n","  for idx,tag in enumerate(labels):\n","    f.write(str(idx))\n","    f.write(\",\")\n","    f.write(tag)\n","    f.write(\"\\n\")"],"execution_count":null,"outputs":[]}]}