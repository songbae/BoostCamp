{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy import signal \n",
    "from tqdm import tqdm \n",
    "from numpy.fft import fft,fftshift\n",
    "import random \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./open/train_features.csv')\n",
    "train_label=pd.read_csv('./open/train_labels.csv')\n",
    "test=pd.read_csv('./open/test_features.csv')\n",
    "submission=pd.read_csv('./open/sample_submission.csv')\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_Energy']=(train['acc_x']**2+train['acc_y']**2+train['acc_z']**2)**(1/3)\n",
    "test['acc_Energy']=(test['acc_x']**2+test['acc_y']**2+test['acc_z']**2)**(1/3)\n",
    "\n",
    "train['gy_Energy']=(train['gy_x']**2+train['gy_y']**2+train['gy_z']**2)**(1/3)\n",
    "test['gy_Energy']=(test['gy_x']**2+test['gy_y']**2+test['gy_z']**2)**(1/3)\n",
    "\n",
    "train['gy_acc_Energy']=((train['gy_x']-train['acc_x'])**2+(train['gy_y']-train['acc_y'])**2+(train['gy_z']-train['acc_z'])**2)**(1/3)\n",
    "test['gy_acc_Energy']=((test['gy_x']-test['acc_x'])**2+(test['gy_y']-test['acc_y'])**2+(test['gy_z']-test['acc_z'])**2)**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.02\n",
    "def jerk_signal(signal):\n",
    "    return np.array([(signal[i+1]-signal[i])/dt for i in range(len(signal)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3125/3125 [00:42<00:00, 73.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dt=list()\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    train_dt.append(temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 782/782 [00:08<00:00, 89.38it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dt=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for v in train.columns[2:]:\n",
    "        values=jerk_signal(temp[v].values)\n",
    "        values=np.insert(values,0,0)\n",
    "        temp.loc[:,v+'_dt']=values\n",
    "    test_dt.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from numpy.fft import *\n",
    "\n",
    "def fourier_transform_one_signal(t_signal):\n",
    "    complex_f_signal= fftpack.fft(t_signal)\n",
    "    amplitude_f_signal=np.abs(complex_f_signal)\n",
    "    return amplitude_f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat(train_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 31/3125 [00:00<00:10, 307.15it/s]<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1875000 entries, 0 to 1874999\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   id                int64  \n",
      " 1   time              int64  \n",
      " 2   acc_x             float64\n",
      " 3   acc_y             float64\n",
      " 4   acc_z             float64\n",
      " 5   gy_x              float64\n",
      " 6   gy_y              float64\n",
      " 7   gy_z              float64\n",
      " 8   acc_Energy        float64\n",
      " 9   gy_Energy         float64\n",
      " 10  gy_acc_Energy     float64\n",
      " 11  acc_x_dt          float64\n",
      " 12  acc_y_dt          float64\n",
      " 13  acc_z_dt          float64\n",
      " 14  gy_x_dt           float64\n",
      " 15  gy_y_dt           float64\n",
      " 16  gy_z_dt           float64\n",
      " 17  acc_Energy_dt     float64\n",
      " 18  gy_Energy_dt      float64\n",
      " 19  gy_acc_Energy_dt  float64\n",
      "dtypes: float64(18), int64(2)\n",
      "memory usage: 300.4 MB\n",
      "100%|██████████| 3125/3125 [00:09<00:00, 316.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "fft=[]\n",
    "for i in tqdm(train['id'].unique()):\n",
    "    temp=train.loc[train['id']==i]\n",
    "    for i in train.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft.append(temp)\n",
    "train=pd.concat(fft)\n",
    "test=pd.concat(test_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 782/782 [00:01<00:00, 529.59it/s]\n"
     ]
    }
   ],
   "source": [
    "fft_t=[]\n",
    "for i in tqdm(test['id'].unique()):\n",
    "    temp=test.loc[test['id']==i]\n",
    "    for i in test.columns[2:8]:\n",
    "        temp[i]=fourier_transform_one_signal(temp[i].values)\n",
    "    fft_t.append(temp)\n",
    "test=pd.concat(fft_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=train.columns\n",
    "train_s=train.copy()\n",
    "test_s=test.copy()\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "train_s.iloc[:,2:]=scaler.fit_transform(train_s.iloc[:,2:])\n",
    "train_sc=pd.DataFrame(data=train_s,columns=col)\n",
    "test_s.iloc[:,2:]=scaler.transform(test_s.iloc[:,2:])\n",
    "test_sc=pd.DataFrame(test_s,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  time      acc_x     acc_y      acc_z      gy_x       gy_y  \\\n",
       "0           0     0  27.356382  8.807207  19.465910  0.376992   0.869226   \n",
       "1           0     1  -0.054866  0.833464   0.820412 -0.282128  -0.093560   \n",
       "2           0     2   0.024046  0.315921   0.081086 -0.182551  -0.053585   \n",
       "3           0     3   0.065632  0.117634  -0.040874 -0.194863   0.154242   \n",
       "4           0     4   0.151477  0.300751   0.317742 -0.350724   0.494539   \n",
       "...       ...   ...        ...       ...        ...       ...        ...   \n",
       "1874995  3124   595   0.365037  0.011656   0.845701  0.080839   0.350395   \n",
       "1874996  3124   596  10.220817  5.476964   7.441373  3.605246  16.530576   \n",
       "1874997  3124   597   0.386337  0.177768  -0.080193 -0.192468  -0.033904   \n",
       "1874998  3124   598   0.728823  0.014037   0.350745  0.136284   1.281790   \n",
       "1874999  3124   599   0.886204  0.075614   1.107553 -0.182228   0.894062   \n",
       "\n",
       "              gy_z  acc_Energy  gy_Energy  gy_acc_Energy  acc_x_dt  acc_y_dt  \\\n",
       "0         0.150423    0.495681  -0.272719      -0.276391  0.000027  0.000298   \n",
       "1         0.011266    0.742974  -0.236152      -0.240632  0.416836 -0.118821   \n",
       "2        -0.003708    0.819822  -0.169815      -0.173080  0.086405  0.023750   \n",
       "3         0.005408    0.785669  -0.035229      -0.040560 -0.058780 -0.213920   \n",
       "4         0.154354    0.791528   0.021954       0.016872  0.039823  0.259227   \n",
       "...            ...         ...        ...            ...       ...       ...   \n",
       "1874995   0.112282   -0.138940   0.829394       0.823900  0.151679  0.037205   \n",
       "1874996  11.843241   -0.167578   0.814816       0.809618  0.150658 -0.000363   \n",
       "1874997  -0.227861   -0.151875   0.802027       0.797338  0.093524 -0.049283   \n",
       "1874998   0.403540   -0.175811   0.801880       0.797431  0.174681 -0.096564   \n",
       "1874999   0.311408   -0.223043   0.803421       0.799233  0.266539 -0.107081   \n",
       "\n",
       "         acc_z_dt   gy_x_dt   gy_y_dt   gy_z_dt  acc_Energy_dt  gy_Energy_dt  \\\n",
       "0       -0.000433  0.000347  0.000373  0.000273       0.000101      0.001505   \n",
       "1       -0.255054  0.032738 -0.349095  0.377085       0.564992      0.166566   \n",
       "2       -0.531727 -0.141582 -0.202368 -0.004887       0.175645      0.300944   \n",
       "3        0.285459  0.229520 -0.385106 -0.135647      -0.077915      0.609008   \n",
       "4       -0.055206  0.057320 -0.174917 -0.028047       0.013483      0.259626   \n",
       "...           ...       ...       ...       ...            ...           ...   \n",
       "1874995  0.119409 -0.108728 -0.027804 -0.009085      -0.142794      0.063329   \n",
       "1874996  0.265559 -0.027936  0.090560 -0.018412      -0.065316     -0.064300   \n",
       "1874997  0.260884  0.082744  0.123264 -0.152712       0.035970     -0.056225   \n",
       "1874998  0.071332  0.153722 -0.014412 -0.049662      -0.054574      0.000843   \n",
       "1874999  0.079654  0.207388 -0.042034 -0.022996      -0.107792      0.008458   \n",
       "\n",
       "         gy_acc_Energy_dt  \n",
       "0                0.001501  \n",
       "1                0.162871  \n",
       "2                0.306341  \n",
       "3                0.599518  \n",
       "4                0.260669  \n",
       "...                   ...  \n",
       "1874995          0.063674  \n",
       "1874996         -0.062949  \n",
       "1874997         -0.053918  \n",
       "1874998          0.001922  \n",
       "1874999          0.009633  \n",
       "\n",
       "[1875000 rows x 20 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>time</th>\n      <th>acc_x</th>\n      <th>acc_y</th>\n      <th>acc_z</th>\n      <th>gy_x</th>\n      <th>gy_y</th>\n      <th>gy_z</th>\n      <th>acc_Energy</th>\n      <th>gy_Energy</th>\n      <th>gy_acc_Energy</th>\n      <th>acc_x_dt</th>\n      <th>acc_y_dt</th>\n      <th>acc_z_dt</th>\n      <th>gy_x_dt</th>\n      <th>gy_y_dt</th>\n      <th>gy_z_dt</th>\n      <th>acc_Energy_dt</th>\n      <th>gy_Energy_dt</th>\n      <th>gy_acc_Energy_dt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>27.356382</td>\n      <td>8.807207</td>\n      <td>19.465910</td>\n      <td>0.376992</td>\n      <td>0.869226</td>\n      <td>0.150423</td>\n      <td>0.495681</td>\n      <td>-0.272719</td>\n      <td>-0.276391</td>\n      <td>0.000027</td>\n      <td>0.000298</td>\n      <td>-0.000433</td>\n      <td>0.000347</td>\n      <td>0.000373</td>\n      <td>0.000273</td>\n      <td>0.000101</td>\n      <td>0.001505</td>\n      <td>0.001501</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-0.054866</td>\n      <td>0.833464</td>\n      <td>0.820412</td>\n      <td>-0.282128</td>\n      <td>-0.093560</td>\n      <td>0.011266</td>\n      <td>0.742974</td>\n      <td>-0.236152</td>\n      <td>-0.240632</td>\n      <td>0.416836</td>\n      <td>-0.118821</td>\n      <td>-0.255054</td>\n      <td>0.032738</td>\n      <td>-0.349095</td>\n      <td>0.377085</td>\n      <td>0.564992</td>\n      <td>0.166566</td>\n      <td>0.162871</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0.024046</td>\n      <td>0.315921</td>\n      <td>0.081086</td>\n      <td>-0.182551</td>\n      <td>-0.053585</td>\n      <td>-0.003708</td>\n      <td>0.819822</td>\n      <td>-0.169815</td>\n      <td>-0.173080</td>\n      <td>0.086405</td>\n      <td>0.023750</td>\n      <td>-0.531727</td>\n      <td>-0.141582</td>\n      <td>-0.202368</td>\n      <td>-0.004887</td>\n      <td>0.175645</td>\n      <td>0.300944</td>\n      <td>0.306341</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0.065632</td>\n      <td>0.117634</td>\n      <td>-0.040874</td>\n      <td>-0.194863</td>\n      <td>0.154242</td>\n      <td>0.005408</td>\n      <td>0.785669</td>\n      <td>-0.035229</td>\n      <td>-0.040560</td>\n      <td>-0.058780</td>\n      <td>-0.213920</td>\n      <td>0.285459</td>\n      <td>0.229520</td>\n      <td>-0.385106</td>\n      <td>-0.135647</td>\n      <td>-0.077915</td>\n      <td>0.609008</td>\n      <td>0.599518</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0.151477</td>\n      <td>0.300751</td>\n      <td>0.317742</td>\n      <td>-0.350724</td>\n      <td>0.494539</td>\n      <td>0.154354</td>\n      <td>0.791528</td>\n      <td>0.021954</td>\n      <td>0.016872</td>\n      <td>0.039823</td>\n      <td>0.259227</td>\n      <td>-0.055206</td>\n      <td>0.057320</td>\n      <td>-0.174917</td>\n      <td>-0.028047</td>\n      <td>0.013483</td>\n      <td>0.259626</td>\n      <td>0.260669</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1874995</th>\n      <td>3124</td>\n      <td>595</td>\n      <td>0.365037</td>\n      <td>0.011656</td>\n      <td>0.845701</td>\n      <td>0.080839</td>\n      <td>0.350395</td>\n      <td>0.112282</td>\n      <td>-0.138940</td>\n      <td>0.829394</td>\n      <td>0.823900</td>\n      <td>0.151679</td>\n      <td>0.037205</td>\n      <td>0.119409</td>\n      <td>-0.108728</td>\n      <td>-0.027804</td>\n      <td>-0.009085</td>\n      <td>-0.142794</td>\n      <td>0.063329</td>\n      <td>0.063674</td>\n    </tr>\n    <tr>\n      <th>1874996</th>\n      <td>3124</td>\n      <td>596</td>\n      <td>10.220817</td>\n      <td>5.476964</td>\n      <td>7.441373</td>\n      <td>3.605246</td>\n      <td>16.530576</td>\n      <td>11.843241</td>\n      <td>-0.167578</td>\n      <td>0.814816</td>\n      <td>0.809618</td>\n      <td>0.150658</td>\n      <td>-0.000363</td>\n      <td>0.265559</td>\n      <td>-0.027936</td>\n      <td>0.090560</td>\n      <td>-0.018412</td>\n      <td>-0.065316</td>\n      <td>-0.064300</td>\n      <td>-0.062949</td>\n    </tr>\n    <tr>\n      <th>1874997</th>\n      <td>3124</td>\n      <td>597</td>\n      <td>0.386337</td>\n      <td>0.177768</td>\n      <td>-0.080193</td>\n      <td>-0.192468</td>\n      <td>-0.033904</td>\n      <td>-0.227861</td>\n      <td>-0.151875</td>\n      <td>0.802027</td>\n      <td>0.797338</td>\n      <td>0.093524</td>\n      <td>-0.049283</td>\n      <td>0.260884</td>\n      <td>0.082744</td>\n      <td>0.123264</td>\n      <td>-0.152712</td>\n      <td>0.035970</td>\n      <td>-0.056225</td>\n      <td>-0.053918</td>\n    </tr>\n    <tr>\n      <th>1874998</th>\n      <td>3124</td>\n      <td>598</td>\n      <td>0.728823</td>\n      <td>0.014037</td>\n      <td>0.350745</td>\n      <td>0.136284</td>\n      <td>1.281790</td>\n      <td>0.403540</td>\n      <td>-0.175811</td>\n      <td>0.801880</td>\n      <td>0.797431</td>\n      <td>0.174681</td>\n      <td>-0.096564</td>\n      <td>0.071332</td>\n      <td>0.153722</td>\n      <td>-0.014412</td>\n      <td>-0.049662</td>\n      <td>-0.054574</td>\n      <td>0.000843</td>\n      <td>0.001922</td>\n    </tr>\n    <tr>\n      <th>1874999</th>\n      <td>3124</td>\n      <td>599</td>\n      <td>0.886204</td>\n      <td>0.075614</td>\n      <td>1.107553</td>\n      <td>-0.182228</td>\n      <td>0.894062</td>\n      <td>0.311408</td>\n      <td>-0.223043</td>\n      <td>0.803421</td>\n      <td>0.799233</td>\n      <td>0.266539</td>\n      <td>-0.107081</td>\n      <td>0.079654</td>\n      <td>0.207388</td>\n      <td>-0.042034</td>\n      <td>-0.022996</td>\n      <td>-0.107792</td>\n      <td>0.008458</td>\n      <td>0.009633</td>\n    </tr>\n  </tbody>\n</table>\n<p>1875000 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "train_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Bidirectional,Dropout\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K \n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from numpy.random import seed \n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3125, 600, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_sc.shape\n",
    "X=np.array(train_sc.iloc[:,2:]).reshape(3125,600,-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test_x=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        id  label                          label_desc\n0        0     37           Shoulder Press (dumbbell)\n1        1     26                        Non-Exercise\n2        2      3                  Biceps Curl (band)\n3        3     26                        Non-Exercise\n4        4     26                        Non-Exercise\n...    ...    ...                                 ...\n3120  3120     26                        Non-Exercise\n3121  3121     26                        Non-Exercise\n3122  3122     15  Dynamic Stretch (at your own pace)\n3123  3123     26                        Non-Exercise\n3124  3124      2                          Bicep Curl\n\n[3125 rows x 3 columns]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3125, 61)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "print(train_label)\n",
    "y = train_label['label'].values\n",
    "y = tf.keras.utils.to_categorical(train_label['label']) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(input_shape,classes):\n",
    "    seed(2021)\n",
    "    tf.random.set_seed(20201)\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    conv1 = keras.layers.Conv1D(filters=128, kernel_size=9, padding='same')(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.Activation(activation='relu')(conv1)\n",
    "    conv1 = keras.layers.Dropout(rate=0.3)(conv1)\n",
    "\n",
    "    conv2 = keras.layers.Conv1D(filters=256, kernel_size=6, padding='same')(conv1)\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.layers.Activation('relu')(conv2)\n",
    "    conv2 = keras.layers.Dropout(rate=0.4)(conv2)\n",
    "    \n",
    "    conv3 = keras.layers.Conv1D(128, kernel_size=3,padding='same')(conv2)\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    conv3 = keras.layers.Activation('relu')(conv3)\n",
    "    conv3 = keras.layers.Dropout(rate=0.5)(conv3)\n",
    "    \n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\n",
    "    \n",
    "    output_layer = keras.layers.Dense(classes, activation='softmax')(gap)\n",
    "    \n",
    "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(), \n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9ms/step - loss: 0.5786 - accuracy: 0.8303 - val_loss: 0.7774 - val_accuracy: 0.8051\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.5427 - accuracy: 0.8495 - val_loss: 0.7549 - val_accuracy: 0.7955\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.5159 - accuracy: 0.8511 - val_loss: 0.7109 - val_accuracy: 0.7923\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4848 - accuracy: 0.8521 - val_loss: 0.7291 - val_accuracy: 0.7764\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.4892 - accuracy: 0.8524 - val_loss: 0.7152 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4858 - accuracy: 0.8504 - val_loss: 0.6632 - val_accuracy: 0.8083\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4387 - accuracy: 0.8708 - val_loss: 0.6621 - val_accuracy: 0.8051\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4459 - accuracy: 0.8641 - val_loss: 0.6507 - val_accuracy: 0.8115\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.4372 - accuracy: 0.8758 - val_loss: 0.6243 - val_accuracy: 0.8307\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3971 - accuracy: 0.8872 - val_loss: 0.6733 - val_accuracy: 0.8179\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.4485 - accuracy: 0.8691 - val_loss: 0.6433 - val_accuracy: 0.8211\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3961 - accuracy: 0.8725 - val_loss: 0.6429 - val_accuracy: 0.7955\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3700 - accuracy: 0.8910 - val_loss: 0.6453 - val_accuracy: 0.8147\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3561 - accuracy: 0.8963 - val_loss: 0.6220 - val_accuracy: 0.8275\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3457 - accuracy: 0.9004 - val_loss: 0.5832 - val_accuracy: 0.8530\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3140 - accuracy: 0.9085 - val_loss: 0.5866 - val_accuracy: 0.8339\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3119 - accuracy: 0.9157 - val_loss: 0.6127 - val_accuracy: 0.8339\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2969 - accuracy: 0.9109 - val_loss: 0.5965 - val_accuracy: 0.8211\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3066 - accuracy: 0.9173 - val_loss: 0.5735 - val_accuracy: 0.8403\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3038 - accuracy: 0.9161 - val_loss: 0.5964 - val_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2753 - accuracy: 0.9228 - val_loss: 0.5727 - val_accuracy: 0.8307\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2998 - accuracy: 0.9249 - val_loss: 0.5934 - val_accuracy: 0.8179\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2884 - accuracy: 0.9179 - val_loss: 0.5814 - val_accuracy: 0.8466\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2705 - accuracy: 0.9315 - val_loss: 0.5752 - val_accuracy: 0.8498\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2707 - accuracy: 0.9284 - val_loss: 0.5880 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2588 - accuracy: 0.9324 - val_loss: 0.5555 - val_accuracy: 0.8435\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2623 - accuracy: 0.9302 - val_loss: 0.5675 - val_accuracy: 0.8371\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2752 - accuracy: 0.9253 - val_loss: 0.5506 - val_accuracy: 0.8435\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2576 - accuracy: 0.9263 - val_loss: 0.5410 - val_accuracy: 0.8562\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2629 - accuracy: 0.9284 - val_loss: 0.5934 - val_accuracy: 0.8403\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2259 - accuracy: 0.9471 - val_loss: 0.5529 - val_accuracy: 0.8498\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2482 - accuracy: 0.9372 - val_loss: 0.5330 - val_accuracy: 0.8498\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2412 - accuracy: 0.9388 - val_loss: 0.5557 - val_accuracy: 0.8498\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2386 - accuracy: 0.9402 - val_loss: 0.5651 - val_accuracy: 0.8307\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2374 - accuracy: 0.9408 - val_loss: 0.5560 - val_accuracy: 0.8339\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2253 - accuracy: 0.9501 - val_loss: 0.5623 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2344 - accuracy: 0.9414 - val_loss: 0.5493 - val_accuracy: 0.8403\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2272 - accuracy: 0.9492 - val_loss: 0.5364 - val_accuracy: 0.8530\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2104 - accuracy: 0.9473 - val_loss: 0.5377 - val_accuracy: 0.8466\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2233 - accuracy: 0.9470 - val_loss: 0.5501 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5330 - accuracy: 0.8498\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5330 - accuracy: 0.8498\n",
      "--------------------Fold_2--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 53ms/step - loss: 3.4234 - accuracy: 0.3636 - val_loss: 3.4081 - val_accuracy: 0.2652\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.9913 - accuracy: 0.5488 - val_loss: 1.8784 - val_accuracy: 0.5431\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.7127 - accuracy: 0.5827 - val_loss: 2.0214 - val_accuracy: 0.5431\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5513 - accuracy: 0.6138 - val_loss: 1.9794 - val_accuracy: 0.5399\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.3946 - accuracy: 0.6439 - val_loss: 1.6094 - val_accuracy: 0.5879\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3005 - accuracy: 0.6633 - val_loss: 1.3688 - val_accuracy: 0.6134\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.1931 - accuracy: 0.6886 - val_loss: 1.3489 - val_accuracy: 0.6486\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0985 - accuracy: 0.7096 - val_loss: 1.1035 - val_accuracy: 0.7029\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9584 - accuracy: 0.7437 - val_loss: 1.1549 - val_accuracy: 0.7029\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9125 - accuracy: 0.7524 - val_loss: 0.9936 - val_accuracy: 0.7284\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8543 - accuracy: 0.7697 - val_loss: 0.9691 - val_accuracy: 0.7316\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8057 - accuracy: 0.7696 - val_loss: 0.8517 - val_accuracy: 0.7764\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7721 - accuracy: 0.7869 - val_loss: 0.8122 - val_accuracy: 0.7827\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7050 - accuracy: 0.8056 - val_loss: 0.7963 - val_accuracy: 0.7636\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6331 - accuracy: 0.8236 - val_loss: 0.7565 - val_accuracy: 0.7891\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.6640 - accuracy: 0.8277 - val_loss: 0.7690 - val_accuracy: 0.7987\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6253 - accuracy: 0.8310 - val_loss: 0.6953 - val_accuracy: 0.7987\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5521 - accuracy: 0.8440 - val_loss: 0.6547 - val_accuracy: 0.8403\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5522 - accuracy: 0.8320 - val_loss: 0.6456 - val_accuracy: 0.8147\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.5605 - accuracy: 0.8357 - val_loss: 0.6214 - val_accuracy: 0.8147\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5047 - accuracy: 0.8577 - val_loss: 0.6743 - val_accuracy: 0.8211\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.4887 - accuracy: 0.8577 - val_loss: 0.6662 - val_accuracy: 0.7859\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4754 - accuracy: 0.8550 - val_loss: 0.6002 - val_accuracy: 0.8243\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.4395 - accuracy: 0.8723 - val_loss: 0.5841 - val_accuracy: 0.8339\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4493 - accuracy: 0.8797 - val_loss: 0.6106 - val_accuracy: 0.8243\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4457 - accuracy: 0.8630 - val_loss: 0.6208 - val_accuracy: 0.8307\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4310 - accuracy: 0.8820 - val_loss: 0.5543 - val_accuracy: 0.8498\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3945 - accuracy: 0.8851 - val_loss: 0.5890 - val_accuracy: 0.8243\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3823 - accuracy: 0.8938 - val_loss: 0.5775 - val_accuracy: 0.8243\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3833 - accuracy: 0.8856 - val_loss: 0.5350 - val_accuracy: 0.8466\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3708 - accuracy: 0.9000 - val_loss: 0.5411 - val_accuracy: 0.8307\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3698 - accuracy: 0.9001 - val_loss: 0.6277 - val_accuracy: 0.8243\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3388 - accuracy: 0.9067 - val_loss: 0.5551 - val_accuracy: 0.8466\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3369 - accuracy: 0.8925 - val_loss: 0.5013 - val_accuracy: 0.8530\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3345 - accuracy: 0.9021 - val_loss: 0.5067 - val_accuracy: 0.8435\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3210 - accuracy: 0.9113 - val_loss: 0.5277 - val_accuracy: 0.8339\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3454 - accuracy: 0.8970 - val_loss: 0.5822 - val_accuracy: 0.8083\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3421 - accuracy: 0.8983 - val_loss: 0.5728 - val_accuracy: 0.8371\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2896 - accuracy: 0.9199 - val_loss: 0.4949 - val_accuracy: 0.8530\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2648 - accuracy: 0.9316 - val_loss: 0.5250 - val_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2635 - accuracy: 0.9301 - val_loss: 0.5074 - val_accuracy: 0.8498\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2635 - accuracy: 0.9281 - val_loss: 0.5225 - val_accuracy: 0.8371\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2528 - accuracy: 0.9380 - val_loss: 0.4897 - val_accuracy: 0.8562\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2628 - accuracy: 0.9264 - val_loss: 0.5427 - val_accuracy: 0.8466\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2502 - accuracy: 0.9287 - val_loss: 0.4788 - val_accuracy: 0.8690\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2570 - accuracy: 0.9283 - val_loss: 0.5030 - val_accuracy: 0.8435\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2403 - accuracy: 0.9409 - val_loss: 0.4786 - val_accuracy: 0.8594\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2346 - accuracy: 0.9304 - val_loss: 0.4896 - val_accuracy: 0.8562\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2311 - accuracy: 0.9371 - val_loss: 0.4956 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2407 - accuracy: 0.9341 - val_loss: 0.4918 - val_accuracy: 0.8594\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2241 - accuracy: 0.9454 - val_loss: 0.4812 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2221 - accuracy: 0.9400 - val_loss: 0.4754 - val_accuracy: 0.8498\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2154 - accuracy: 0.9478 - val_loss: 0.4918 - val_accuracy: 0.8530\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2090 - accuracy: 0.9500 - val_loss: 0.4662 - val_accuracy: 0.8562\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2184 - accuracy: 0.9460 - val_loss: 0.4826 - val_accuracy: 0.8562\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1868 - accuracy: 0.9544 - val_loss: 0.4909 - val_accuracy: 0.8466\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2121 - accuracy: 0.9415 - val_loss: 0.4866 - val_accuracy: 0.8626\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1989 - accuracy: 0.9449 - val_loss: 0.4701 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1912 - accuracy: 0.9516 - val_loss: 0.4557 - val_accuracy: 0.8594\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1760 - accuracy: 0.9607 - val_loss: 0.4630 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1804 - accuracy: 0.9603 - val_loss: 0.4564 - val_accuracy: 0.8530\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1983 - accuracy: 0.9472 - val_loss: 0.4629 - val_accuracy: 0.8562\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1814 - accuracy: 0.9563 - val_loss: 0.4711 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1903 - accuracy: 0.9558 - val_loss: 0.4533 - val_accuracy: 0.8530\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1789 - accuracy: 0.9565 - val_loss: 0.4562 - val_accuracy: 0.8530\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1837 - accuracy: 0.9578 - val_loss: 0.4548 - val_accuracy: 0.8594\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1612 - accuracy: 0.9654 - val_loss: 0.4526 - val_accuracy: 0.8498\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1873 - accuracy: 0.9613 - val_loss: 0.4588 - val_accuracy: 0.8562\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1667 - accuracy: 0.9611 - val_loss: 0.4590 - val_accuracy: 0.8530\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1668 - accuracy: 0.9610 - val_loss: 0.4620 - val_accuracy: 0.8594\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1792 - accuracy: 0.9575 - val_loss: 0.4581 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1957 - accuracy: 0.9485 - val_loss: 0.4568 - val_accuracy: 0.8562\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1761 - accuracy: 0.9596 - val_loss: 0.4579 - val_accuracy: 0.8498\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1731 - accuracy: 0.9619 - val_loss: 0.4569 - val_accuracy: 0.8530\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1741 - accuracy: 0.9574 - val_loss: 0.4566 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8498\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8498\n",
      "--------------------Fold_3--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 4s 58ms/step - loss: 3.3651 - accuracy: 0.3435 - val_loss: 3.1009 - val_accuracy: 0.3770\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.9939 - accuracy: 0.5423 - val_loss: 1.8851 - val_accuracy: 0.5463\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.7704 - accuracy: 0.5671 - val_loss: 1.8847 - val_accuracy: 0.5463\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5069 - accuracy: 0.6212 - val_loss: 1.7431 - val_accuracy: 0.5847\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3818 - accuracy: 0.6503 - val_loss: 1.6641 - val_accuracy: 0.5847\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2809 - accuracy: 0.6664 - val_loss: 1.3860 - val_accuracy: 0.6358\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.1434 - accuracy: 0.6832 - val_loss: 1.3966 - val_accuracy: 0.6422\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0385 - accuracy: 0.7305 - val_loss: 1.1334 - val_accuracy: 0.6741\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9987 - accuracy: 0.7291 - val_loss: 1.0865 - val_accuracy: 0.6901\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.9200 - accuracy: 0.7537 - val_loss: 0.9541 - val_accuracy: 0.7412\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9108 - accuracy: 0.7422 - val_loss: 0.8889 - val_accuracy: 0.7540\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.8295 - accuracy: 0.7556 - val_loss: 0.8861 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7494 - accuracy: 0.7970 - val_loss: 0.8204 - val_accuracy: 0.7732\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7204 - accuracy: 0.8020 - val_loss: 0.7764 - val_accuracy: 0.7923\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6629 - accuracy: 0.8151 - val_loss: 0.7136 - val_accuracy: 0.8051\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6308 - accuracy: 0.8186 - val_loss: 0.7574 - val_accuracy: 0.8051\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6029 - accuracy: 0.8204 - val_loss: 0.6613 - val_accuracy: 0.8243\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5981 - accuracy: 0.8264 - val_loss: 0.7036 - val_accuracy: 0.8051\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5921 - accuracy: 0.8300 - val_loss: 0.7215 - val_accuracy: 0.8083\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.5505 - accuracy: 0.8408 - val_loss: 0.6824 - val_accuracy: 0.8083\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5069 - accuracy: 0.8482 - val_loss: 0.6242 - val_accuracy: 0.8083\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4948 - accuracy: 0.8655 - val_loss: 0.5805 - val_accuracy: 0.8147\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4651 - accuracy: 0.8532 - val_loss: 0.6170 - val_accuracy: 0.8115\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4594 - accuracy: 0.8695 - val_loss: 0.5839 - val_accuracy: 0.8243\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4685 - accuracy: 0.8639 - val_loss: 0.5459 - val_accuracy: 0.8371\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4654 - accuracy: 0.8694 - val_loss: 0.5194 - val_accuracy: 0.8562\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4271 - accuracy: 0.8675 - val_loss: 0.5481 - val_accuracy: 0.8403\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4024 - accuracy: 0.8759 - val_loss: 0.5817 - val_accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4293 - accuracy: 0.8785 - val_loss: 0.5813 - val_accuracy: 0.8179\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3969 - accuracy: 0.8835 - val_loss: 0.5291 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3729 - accuracy: 0.8931 - val_loss: 0.5004 - val_accuracy: 0.8435\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3432 - accuracy: 0.8976 - val_loss: 0.4883 - val_accuracy: 0.8530\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3462 - accuracy: 0.8948 - val_loss: 0.4669 - val_accuracy: 0.8530\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3384 - accuracy: 0.9038 - val_loss: 0.4984 - val_accuracy: 0.8371\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3039 - accuracy: 0.9117 - val_loss: 0.4808 - val_accuracy: 0.8466\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3056 - accuracy: 0.9095 - val_loss: 0.4654 - val_accuracy: 0.8562\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3284 - accuracy: 0.9076 - val_loss: 0.4661 - val_accuracy: 0.8658\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3090 - accuracy: 0.9204 - val_loss: 0.4506 - val_accuracy: 0.8562\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3072 - accuracy: 0.9101 - val_loss: 0.4742 - val_accuracy: 0.8530\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2961 - accuracy: 0.9130 - val_loss: 0.4710 - val_accuracy: 0.8403\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3149 - accuracy: 0.9119 - val_loss: 0.5178 - val_accuracy: 0.8211\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3027 - accuracy: 0.9166 - val_loss: 0.4811 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2691 - accuracy: 0.9313 - val_loss: 0.4510 - val_accuracy: 0.8594\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2674 - accuracy: 0.9235 - val_loss: 0.4648 - val_accuracy: 0.8594\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2683 - accuracy: 0.9282 - val_loss: 0.4551 - val_accuracy: 0.8498\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2750 - accuracy: 0.9287 - val_loss: 0.4387 - val_accuracy: 0.8754\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2553 - accuracy: 0.9256 - val_loss: 0.4634 - val_accuracy: 0.8690\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2490 - accuracy: 0.9344 - val_loss: 0.4488 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2586 - accuracy: 0.9300 - val_loss: 0.4384 - val_accuracy: 0.8690\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2661 - accuracy: 0.9228 - val_loss: 0.4376 - val_accuracy: 0.8722\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2407 - accuracy: 0.9382 - val_loss: 0.4470 - val_accuracy: 0.8882\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2447 - accuracy: 0.9346 - val_loss: 0.4557 - val_accuracy: 0.8498\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2366 - accuracy: 0.9317 - val_loss: 0.4253 - val_accuracy: 0.8722\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2289 - accuracy: 0.9404 - val_loss: 0.4624 - val_accuracy: 0.8594\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2395 - accuracy: 0.9316 - val_loss: 0.4260 - val_accuracy: 0.8786\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2319 - accuracy: 0.9400 - val_loss: 0.4367 - val_accuracy: 0.8722\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2356 - accuracy: 0.9389 - val_loss: 0.4362 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2131 - accuracy: 0.9444 - val_loss: 0.4256 - val_accuracy: 0.8690\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2233 - accuracy: 0.9458 - val_loss: 0.4249 - val_accuracy: 0.8754\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2223 - accuracy: 0.9450 - val_loss: 0.4199 - val_accuracy: 0.8690\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2130 - accuracy: 0.9483 - val_loss: 0.4283 - val_accuracy: 0.8754\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2236 - accuracy: 0.9403 - val_loss: 0.4180 - val_accuracy: 0.8722\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2207 - accuracy: 0.9494 - val_loss: 0.4230 - val_accuracy: 0.8786\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2310 - accuracy: 0.9392 - val_loss: 0.4131 - val_accuracy: 0.8722\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2314 - accuracy: 0.9375 - val_loss: 0.4103 - val_accuracy: 0.8786\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2233 - accuracy: 0.9431 - val_loss: 0.4126 - val_accuracy: 0.8882\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2459 - accuracy: 0.9298 - val_loss: 0.4136 - val_accuracy: 0.8754\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2066 - accuracy: 0.9472 - val_loss: 0.4115 - val_accuracy: 0.8818\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2074 - accuracy: 0.9476 - val_loss: 0.4256 - val_accuracy: 0.8690\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1991 - accuracy: 0.9556 - val_loss: 0.4077 - val_accuracy: 0.8754\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1993 - accuracy: 0.9498 - val_loss: 0.4115 - val_accuracy: 0.8754\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1950 - accuracy: 0.9520 - val_loss: 0.4072 - val_accuracy: 0.8882\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2081 - accuracy: 0.9465 - val_loss: 0.4142 - val_accuracy: 0.8850\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2026 - accuracy: 0.9500 - val_loss: 0.4097 - val_accuracy: 0.8882\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2016 - accuracy: 0.9501 - val_loss: 0.4093 - val_accuracy: 0.8786\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2188 - accuracy: 0.9490 - val_loss: 0.4086 - val_accuracy: 0.8786\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2137 - accuracy: 0.9410 - val_loss: 0.4058 - val_accuracy: 0.8882\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2094 - accuracy: 0.9486 - val_loss: 0.4045 - val_accuracy: 0.8914\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1868 - accuracy: 0.9549 - val_loss: 0.4054 - val_accuracy: 0.8850\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1976 - accuracy: 0.9440 - val_loss: 0.4090 - val_accuracy: 0.8850\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2053 - accuracy: 0.9495 - val_loss: 0.4050 - val_accuracy: 0.8882\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2150 - accuracy: 0.9500 - val_loss: 0.4064 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1952 - accuracy: 0.9549 - val_loss: 0.4052 - val_accuracy: 0.8850\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2027 - accuracy: 0.9472 - val_loss: 0.4042 - val_accuracy: 0.8850\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2099 - accuracy: 0.9460 - val_loss: 0.4037 - val_accuracy: 0.8818\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1909 - accuracy: 0.9542 - val_loss: 0.4061 - val_accuracy: 0.8818\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1900 - accuracy: 0.9565 - val_loss: 0.4054 - val_accuracy: 0.8882\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2018 - accuracy: 0.9525 - val_loss: 0.4052 - val_accuracy: 0.8850\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1937 - accuracy: 0.9490 - val_loss: 0.4060 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2007 - accuracy: 0.9516 - val_loss: 0.4046 - val_accuracy: 0.8850\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.1986 - accuracy: 0.9576 - val_loss: 0.4056 - val_accuracy: 0.8850\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2083 - accuracy: 0.9526 - val_loss: 0.4049 - val_accuracy: 0.8850\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2170 - accuracy: 0.9442 - val_loss: 0.4049 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4037 - accuracy: 0.8818\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4037 - accuracy: 0.8818\n",
      "--------------------Fold_4--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 54ms/step - loss: 3.3323 - accuracy: 0.3583 - val_loss: 3.1899 - val_accuracy: 0.3387\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.9266 - accuracy: 0.5535 - val_loss: 1.9646 - val_accuracy: 0.5367\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.7322 - accuracy: 0.5822 - val_loss: 2.0799 - val_accuracy: 0.5335\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.4805 - accuracy: 0.6323 - val_loss: 1.9023 - val_accuracy: 0.5367\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3670 - accuracy: 0.6523 - val_loss: 1.5279 - val_accuracy: 0.5942\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2687 - accuracy: 0.6786 - val_loss: 1.5615 - val_accuracy: 0.5879\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.1151 - accuracy: 0.7036 - val_loss: 1.2980 - val_accuracy: 0.6518\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0079 - accuracy: 0.7273 - val_loss: 1.2710 - val_accuracy: 0.6550\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9409 - accuracy: 0.7554 - val_loss: 1.2313 - val_accuracy: 0.6581\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9358 - accuracy: 0.7417 - val_loss: 1.1145 - val_accuracy: 0.6901\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8643 - accuracy: 0.7604 - val_loss: 0.9831 - val_accuracy: 0.7316\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7914 - accuracy: 0.7763 - val_loss: 0.9967 - val_accuracy: 0.7157\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7385 - accuracy: 0.7925 - val_loss: 0.9035 - val_accuracy: 0.7540\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6817 - accuracy: 0.8091 - val_loss: 0.8926 - val_accuracy: 0.7380\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6419 - accuracy: 0.8192 - val_loss: 0.9024 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6178 - accuracy: 0.8167 - val_loss: 0.8333 - val_accuracy: 0.7732\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5759 - accuracy: 0.8403 - val_loss: 0.8595 - val_accuracy: 0.7668\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5758 - accuracy: 0.8407 - val_loss: 0.8180 - val_accuracy: 0.7732\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5733 - accuracy: 0.8443 - val_loss: 0.8419 - val_accuracy: 0.7604\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5244 - accuracy: 0.8428 - val_loss: 0.7699 - val_accuracy: 0.7955\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5261 - accuracy: 0.8446 - val_loss: 0.7869 - val_accuracy: 0.7636\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4716 - accuracy: 0.8650 - val_loss: 0.7648 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4741 - accuracy: 0.8522 - val_loss: 0.7395 - val_accuracy: 0.7796\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4552 - accuracy: 0.8681 - val_loss: 0.6930 - val_accuracy: 0.8019\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4367 - accuracy: 0.8752 - val_loss: 0.7237 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4161 - accuracy: 0.8832 - val_loss: 0.7371 - val_accuracy: 0.7668\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4072 - accuracy: 0.8826 - val_loss: 0.7060 - val_accuracy: 0.8115\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3966 - accuracy: 0.8837 - val_loss: 0.6930 - val_accuracy: 0.8115\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3596 - accuracy: 0.9037 - val_loss: 0.6745 - val_accuracy: 0.8211\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3574 - accuracy: 0.9064 - val_loss: 0.7019 - val_accuracy: 0.8019\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3241 - accuracy: 0.9120 - val_loss: 0.6520 - val_accuracy: 0.8115\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3635 - accuracy: 0.8914 - val_loss: 0.6700 - val_accuracy: 0.7987\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3205 - accuracy: 0.9071 - val_loss: 0.6443 - val_accuracy: 0.8147\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3480 - accuracy: 0.9086 - val_loss: 0.6397 - val_accuracy: 0.8275\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3237 - accuracy: 0.9084 - val_loss: 0.6696 - val_accuracy: 0.8179\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3268 - accuracy: 0.9101 - val_loss: 0.6522 - val_accuracy: 0.8147\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2912 - accuracy: 0.9238 - val_loss: 0.6105 - val_accuracy: 0.8243\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3052 - accuracy: 0.9185 - val_loss: 0.6231 - val_accuracy: 0.8339\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3112 - accuracy: 0.9086 - val_loss: 0.6884 - val_accuracy: 0.8115\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3007 - accuracy: 0.9091 - val_loss: 0.6126 - val_accuracy: 0.8243\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2777 - accuracy: 0.9261 - val_loss: 0.6623 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2670 - accuracy: 0.9330 - val_loss: 0.6335 - val_accuracy: 0.8179\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2605 - accuracy: 0.9252 - val_loss: 0.6268 - val_accuracy: 0.8211\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2531 - accuracy: 0.9390 - val_loss: 0.6459 - val_accuracy: 0.8051\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2638 - accuracy: 0.9280 - val_loss: 0.6417 - val_accuracy: 0.8019\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.8243\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.8243\n",
      "--------------------Fold_5--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 53ms/step - loss: 3.3518 - accuracy: 0.3786 - val_loss: 3.2947 - val_accuracy: 0.3195\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.9854 - accuracy: 0.5464 - val_loss: 2.0049 - val_accuracy: 0.5495\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.7756 - accuracy: 0.5669 - val_loss: 1.9386 - val_accuracy: 0.5527\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5831 - accuracy: 0.6079 - val_loss: 1.8298 - val_accuracy: 0.5655\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3660 - accuracy: 0.6553 - val_loss: 1.6974 - val_accuracy: 0.5815\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.2285 - accuracy: 0.6863 - val_loss: 1.4714 - val_accuracy: 0.6134\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.1476 - accuracy: 0.6934 - val_loss: 1.2720 - val_accuracy: 0.6422\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.0701 - accuracy: 0.7235 - val_loss: 1.2178 - val_accuracy: 0.6550\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9851 - accuracy: 0.7366 - val_loss: 1.0920 - val_accuracy: 0.6805\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8580 - accuracy: 0.7817 - val_loss: 1.0891 - val_accuracy: 0.6741\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8340 - accuracy: 0.7700 - val_loss: 0.9651 - val_accuracy: 0.7029\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8368 - accuracy: 0.7671 - val_loss: 0.9251 - val_accuracy: 0.7444\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.7543 - accuracy: 0.7906 - val_loss: 0.8900 - val_accuracy: 0.7572\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.7100 - accuracy: 0.8107 - val_loss: 0.8742 - val_accuracy: 0.7188\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6740 - accuracy: 0.8224 - val_loss: 0.8140 - val_accuracy: 0.7700\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6495 - accuracy: 0.8170 - val_loss: 0.7873 - val_accuracy: 0.7508\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.6389 - accuracy: 0.8257 - val_loss: 0.7621 - val_accuracy: 0.7827\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5857 - accuracy: 0.8331 - val_loss: 0.7394 - val_accuracy: 0.7859\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5553 - accuracy: 0.8512 - val_loss: 0.7068 - val_accuracy: 0.7891\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5474 - accuracy: 0.8506 - val_loss: 0.6756 - val_accuracy: 0.8115\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5133 - accuracy: 0.8503 - val_loss: 0.6958 - val_accuracy: 0.7668\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5011 - accuracy: 0.8587 - val_loss: 0.6451 - val_accuracy: 0.7987\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4701 - accuracy: 0.8614 - val_loss: 0.6444 - val_accuracy: 0.8115\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4421 - accuracy: 0.8775 - val_loss: 0.6583 - val_accuracy: 0.7764\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.4294 - accuracy: 0.8682 - val_loss: 0.6167 - val_accuracy: 0.8147\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4396 - accuracy: 0.8707 - val_loss: 0.6035 - val_accuracy: 0.8179\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4090 - accuracy: 0.8773 - val_loss: 0.6594 - val_accuracy: 0.7987\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4113 - accuracy: 0.8828 - val_loss: 0.6116 - val_accuracy: 0.8307\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.3886 - accuracy: 0.8867 - val_loss: 0.5962 - val_accuracy: 0.8051\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.4038 - accuracy: 0.8850 - val_loss: 0.5464 - val_accuracy: 0.8179\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.3506 - accuracy: 0.8974 - val_loss: 0.6148 - val_accuracy: 0.8083\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.3821 - accuracy: 0.8915 - val_loss: 0.5683 - val_accuracy: 0.8307\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3389 - accuracy: 0.9049 - val_loss: 0.5434 - val_accuracy: 0.8435\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3410 - accuracy: 0.9014 - val_loss: 0.5558 - val_accuracy: 0.8147\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3253 - accuracy: 0.9052 - val_loss: 0.5624 - val_accuracy: 0.8243\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.3416 - accuracy: 0.8977 - val_loss: 0.5084 - val_accuracy: 0.8371\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3008 - accuracy: 0.9162 - val_loss: 0.6142 - val_accuracy: 0.8019\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3384 - accuracy: 0.9009 - val_loss: 0.6146 - val_accuracy: 0.8147\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3161 - accuracy: 0.9088 - val_loss: 0.5173 - val_accuracy: 0.8211\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2844 - accuracy: 0.9122 - val_loss: 0.5987 - val_accuracy: 0.8275\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2954 - accuracy: 0.9151 - val_loss: 0.4888 - val_accuracy: 0.8371\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2482 - accuracy: 0.9282 - val_loss: 0.4976 - val_accuracy: 0.8339\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2660 - accuracy: 0.9223 - val_loss: 0.5048 - val_accuracy: 0.8466\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2616 - accuracy: 0.9292 - val_loss: 0.5234 - val_accuracy: 0.8371\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2710 - accuracy: 0.9167 - val_loss: 0.5044 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2341 - accuracy: 0.9374 - val_loss: 0.4829 - val_accuracy: 0.8403\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2379 - accuracy: 0.9315 - val_loss: 0.4895 - val_accuracy: 0.8371\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2403 - accuracy: 0.9344 - val_loss: 0.4818 - val_accuracy: 0.8403\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1983 - accuracy: 0.9548 - val_loss: 0.4817 - val_accuracy: 0.8466\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2112 - accuracy: 0.9428 - val_loss: 0.4662 - val_accuracy: 0.8435\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2091 - accuracy: 0.9515 - val_loss: 0.4700 - val_accuracy: 0.8562\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2100 - accuracy: 0.9489 - val_loss: 0.4673 - val_accuracy: 0.8403\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2022 - accuracy: 0.9503 - val_loss: 0.5090 - val_accuracy: 0.8371\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1969 - accuracy: 0.9500 - val_loss: 0.4777 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2095 - accuracy: 0.9434 - val_loss: 0.4611 - val_accuracy: 0.8435\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2115 - accuracy: 0.9491 - val_loss: 0.4617 - val_accuracy: 0.8403\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2042 - accuracy: 0.9514 - val_loss: 0.4540 - val_accuracy: 0.8466\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2101 - accuracy: 0.9416 - val_loss: 0.4599 - val_accuracy: 0.8562\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1926 - accuracy: 0.9495 - val_loss: 0.4672 - val_accuracy: 0.8435\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1995 - accuracy: 0.9496 - val_loss: 0.4526 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1869 - accuracy: 0.9546 - val_loss: 0.4640 - val_accuracy: 0.8594\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1949 - accuracy: 0.9486 - val_loss: 0.4741 - val_accuracy: 0.8403\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2133 - accuracy: 0.9421 - val_loss: 0.4605 - val_accuracy: 0.8498\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1873 - accuracy: 0.9533 - val_loss: 0.4593 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1850 - accuracy: 0.9547 - val_loss: 0.4588 - val_accuracy: 0.8435\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1832 - accuracy: 0.9503 - val_loss: 0.4578 - val_accuracy: 0.8403\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1880 - accuracy: 0.9596 - val_loss: 0.4526 - val_accuracy: 0.8498\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.1872 - accuracy: 0.9538 - val_loss: 0.4573 - val_accuracy: 0.8562\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4526 - accuracy: 0.8594\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8594\n",
      "--------------------Fold_6--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 4s 61ms/step - loss: 3.3496 - accuracy: 0.3317 - val_loss: 3.2727 - val_accuracy: 0.2949\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0237 - accuracy: 0.5449 - val_loss: 2.0545 - val_accuracy: 0.5224\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 1.6875 - accuracy: 0.5875 - val_loss: 2.0991 - val_accuracy: 0.5449\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5277 - accuracy: 0.6236 - val_loss: 2.1111 - val_accuracy: 0.5673\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3703 - accuracy: 0.6540 - val_loss: 1.6599 - val_accuracy: 0.5962\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2554 - accuracy: 0.6733 - val_loss: 1.5187 - val_accuracy: 0.6090\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.1247 - accuracy: 0.7131 - val_loss: 1.4118 - val_accuracy: 0.6122\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0499 - accuracy: 0.7194 - val_loss: 1.3270 - val_accuracy: 0.6571\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9824 - accuracy: 0.7291 - val_loss: 1.3523 - val_accuracy: 0.6635\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9082 - accuracy: 0.7415 - val_loss: 1.0844 - val_accuracy: 0.7179\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8268 - accuracy: 0.7713 - val_loss: 0.9941 - val_accuracy: 0.7244\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7833 - accuracy: 0.7840 - val_loss: 0.9764 - val_accuracy: 0.7372\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7218 - accuracy: 0.8116 - val_loss: 1.0469 - val_accuracy: 0.7147\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7217 - accuracy: 0.7946 - val_loss: 0.8997 - val_accuracy: 0.7404\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6618 - accuracy: 0.8120 - val_loss: 0.9096 - val_accuracy: 0.7596\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6408 - accuracy: 0.8115 - val_loss: 0.9110 - val_accuracy: 0.7596\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6038 - accuracy: 0.8303 - val_loss: 0.7956 - val_accuracy: 0.8045\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5811 - accuracy: 0.8317 - val_loss: 0.8157 - val_accuracy: 0.7853\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5742 - accuracy: 0.8347 - val_loss: 0.8892 - val_accuracy: 0.7724\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5255 - accuracy: 0.8378 - val_loss: 0.7517 - val_accuracy: 0.7949\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4984 - accuracy: 0.8534 - val_loss: 0.7765 - val_accuracy: 0.7853\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5142 - accuracy: 0.8487 - val_loss: 0.7318 - val_accuracy: 0.8077\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5060 - accuracy: 0.8465 - val_loss: 0.7701 - val_accuracy: 0.7949\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4740 - accuracy: 0.8631 - val_loss: 0.7951 - val_accuracy: 0.7756\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4330 - accuracy: 0.8722 - val_loss: 0.6617 - val_accuracy: 0.8397\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4235 - accuracy: 0.8732 - val_loss: 0.6796 - val_accuracy: 0.8173\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4064 - accuracy: 0.8822 - val_loss: 0.7119 - val_accuracy: 0.8013\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4429 - accuracy: 0.8726 - val_loss: 0.6853 - val_accuracy: 0.8173\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3931 - accuracy: 0.8773 - val_loss: 0.6504 - val_accuracy: 0.8237\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3703 - accuracy: 0.8928 - val_loss: 0.6759 - val_accuracy: 0.7981\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3738 - accuracy: 0.8896 - val_loss: 0.6796 - val_accuracy: 0.8077\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3710 - accuracy: 0.8854 - val_loss: 0.6791 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3644 - accuracy: 0.8994 - val_loss: 0.7768 - val_accuracy: 0.7821\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3501 - accuracy: 0.9020 - val_loss: 0.6400 - val_accuracy: 0.8237\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2931 - accuracy: 0.9229 - val_loss: 0.6196 - val_accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3087 - accuracy: 0.9219 - val_loss: 0.6062 - val_accuracy: 0.8173\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2757 - accuracy: 0.9265 - val_loss: 0.6205 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2957 - accuracy: 0.9179 - val_loss: 0.6341 - val_accuracy: 0.8237\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2862 - accuracy: 0.9257 - val_loss: 0.6284 - val_accuracy: 0.8269\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2744 - accuracy: 0.9201 - val_loss: 0.5931 - val_accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2715 - accuracy: 0.9188 - val_loss: 0.5823 - val_accuracy: 0.8429\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2563 - accuracy: 0.9238 - val_loss: 0.6063 - val_accuracy: 0.8462\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2571 - accuracy: 0.9254 - val_loss: 0.5831 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2674 - accuracy: 0.9288 - val_loss: 0.6602 - val_accuracy: 0.8141\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2532 - accuracy: 0.9357 - val_loss: 0.6012 - val_accuracy: 0.8301\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2512 - accuracy: 0.9353 - val_loss: 0.5628 - val_accuracy: 0.8494\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2372 - accuracy: 0.9369 - val_loss: 0.5738 - val_accuracy: 0.8526\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2395 - accuracy: 0.9395 - val_loss: 0.6005 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2171 - accuracy: 0.9455 - val_loss: 0.5909 - val_accuracy: 0.8365\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2197 - accuracy: 0.9479 - val_loss: 0.5961 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2402 - accuracy: 0.9416 - val_loss: 0.5806 - val_accuracy: 0.8365\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2206 - accuracy: 0.9397 - val_loss: 0.5634 - val_accuracy: 0.8429\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2129 - accuracy: 0.9493 - val_loss: 0.5690 - val_accuracy: 0.8397\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2119 - accuracy: 0.9488 - val_loss: 0.5836 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5628 - accuracy: 0.8494\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.8494\n",
      "--------------------Fold_7--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 54ms/step - loss: 3.3949 - accuracy: 0.3535 - val_loss: 3.2679 - val_accuracy: 0.3045\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0603 - accuracy: 0.5247 - val_loss: 1.8725 - val_accuracy: 0.5513\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.7874 - accuracy: 0.5539 - val_loss: 2.0437 - val_accuracy: 0.5353\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5553 - accuracy: 0.6179 - val_loss: 1.6768 - val_accuracy: 0.5737\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3470 - accuracy: 0.6564 - val_loss: 1.8031 - val_accuracy: 0.5673\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2673 - accuracy: 0.6671 - val_loss: 1.5339 - val_accuracy: 0.6090\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.1656 - accuracy: 0.6888 - val_loss: 1.3512 - val_accuracy: 0.6378\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0359 - accuracy: 0.7268 - val_loss: 1.1652 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0272 - accuracy: 0.7306 - val_loss: 1.0814 - val_accuracy: 0.6795\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9067 - accuracy: 0.7610 - val_loss: 1.0451 - val_accuracy: 0.7019\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8297 - accuracy: 0.7767 - val_loss: 1.0116 - val_accuracy: 0.6923\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7886 - accuracy: 0.7817 - val_loss: 0.9299 - val_accuracy: 0.7179\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7665 - accuracy: 0.7785 - val_loss: 0.8125 - val_accuracy: 0.7628\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7473 - accuracy: 0.7883 - val_loss: 0.8013 - val_accuracy: 0.7692\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.6592 - accuracy: 0.8192 - val_loss: 0.7517 - val_accuracy: 0.7917\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6741 - accuracy: 0.8117 - val_loss: 0.7349 - val_accuracy: 0.7788\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5668 - accuracy: 0.8324 - val_loss: 0.7700 - val_accuracy: 0.7788\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5949 - accuracy: 0.8327 - val_loss: 0.6970 - val_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5469 - accuracy: 0.8365 - val_loss: 0.7056 - val_accuracy: 0.7885\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5583 - accuracy: 0.8387 - val_loss: 0.6828 - val_accuracy: 0.7981\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5178 - accuracy: 0.8439 - val_loss: 0.6508 - val_accuracy: 0.8173\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5054 - accuracy: 0.8551 - val_loss: 0.6056 - val_accuracy: 0.8237\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4961 - accuracy: 0.8567 - val_loss: 0.6381 - val_accuracy: 0.7917\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4534 - accuracy: 0.8690 - val_loss: 0.6915 - val_accuracy: 0.7853\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4436 - accuracy: 0.8854 - val_loss: 0.6016 - val_accuracy: 0.8045\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4233 - accuracy: 0.8759 - val_loss: 0.5713 - val_accuracy: 0.8173\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4119 - accuracy: 0.8816 - val_loss: 0.5556 - val_accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3863 - accuracy: 0.8932 - val_loss: 0.5800 - val_accuracy: 0.8173\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3683 - accuracy: 0.8923 - val_loss: 0.6546 - val_accuracy: 0.7949\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4089 - accuracy: 0.8837 - val_loss: 0.5802 - val_accuracy: 0.8173\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3608 - accuracy: 0.8865 - val_loss: 0.5549 - val_accuracy: 0.8269\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3443 - accuracy: 0.8955 - val_loss: 0.5390 - val_accuracy: 0.8301\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3680 - accuracy: 0.8951 - val_loss: 0.5182 - val_accuracy: 0.8494\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3422 - accuracy: 0.9003 - val_loss: 0.5548 - val_accuracy: 0.8365\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3301 - accuracy: 0.9000 - val_loss: 0.5475 - val_accuracy: 0.8205\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3287 - accuracy: 0.9063 - val_loss: 0.5873 - val_accuracy: 0.8141\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3311 - accuracy: 0.9020 - val_loss: 0.6468 - val_accuracy: 0.8205\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2963 - accuracy: 0.9150 - val_loss: 0.5346 - val_accuracy: 0.8429\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2768 - accuracy: 0.9280 - val_loss: 0.5209 - val_accuracy: 0.8526\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2725 - accuracy: 0.9240 - val_loss: 0.4907 - val_accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2471 - accuracy: 0.9406 - val_loss: 0.5129 - val_accuracy: 0.8494\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2627 - accuracy: 0.9351 - val_loss: 0.5710 - val_accuracy: 0.8397\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2530 - accuracy: 0.9275 - val_loss: 0.5271 - val_accuracy: 0.8429\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2419 - accuracy: 0.9361 - val_loss: 0.5054 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2540 - accuracy: 0.9311 - val_loss: 0.5149 - val_accuracy: 0.8590\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2364 - accuracy: 0.9427 - val_loss: 0.4891 - val_accuracy: 0.8558\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2225 - accuracy: 0.9424 - val_loss: 0.5073 - val_accuracy: 0.8526\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2328 - accuracy: 0.9390 - val_loss: 0.5004 - val_accuracy: 0.8462\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2216 - accuracy: 0.9435 - val_loss: 0.4799 - val_accuracy: 0.8494\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2309 - accuracy: 0.9327 - val_loss: 0.4800 - val_accuracy: 0.8590\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2188 - accuracy: 0.9455 - val_loss: 0.4952 - val_accuracy: 0.8494\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2294 - accuracy: 0.9448 - val_loss: 0.4766 - val_accuracy: 0.8526\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2128 - accuracy: 0.9430 - val_loss: 0.4955 - val_accuracy: 0.8462\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1900 - accuracy: 0.9573 - val_loss: 0.4991 - val_accuracy: 0.8494\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.2091 - accuracy: 0.9446 - val_loss: 0.4880 - val_accuracy: 0.8365\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2089 - accuracy: 0.9471 - val_loss: 0.4794 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2203 - accuracy: 0.9398 - val_loss: 0.4902 - val_accuracy: 0.8590\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1949 - accuracy: 0.9555 - val_loss: 0.4860 - val_accuracy: 0.8494\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1941 - accuracy: 0.9522 - val_loss: 0.4853 - val_accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1920 - accuracy: 0.9498 - val_loss: 0.4812 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4766 - accuracy: 0.8526\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.8526\n",
      "--------------------Fold_8--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 53ms/step - loss: 3.3662 - accuracy: 0.3450 - val_loss: 3.2530 - val_accuracy: 0.3173\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0203 - accuracy: 0.5477 - val_loss: 1.8857 - val_accuracy: 0.5353\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.7353 - accuracy: 0.5731 - val_loss: 2.1207 - val_accuracy: 0.5513\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5001 - accuracy: 0.6311 - val_loss: 1.6834 - val_accuracy: 0.5673\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3339 - accuracy: 0.6631 - val_loss: 1.8515 - val_accuracy: 0.5897\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2175 - accuracy: 0.6803 - val_loss: 1.3882 - val_accuracy: 0.6378\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 1.2030 - accuracy: 0.6785 - val_loss: 1.1786 - val_accuracy: 0.6635\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.0908 - accuracy: 0.7048 - val_loss: 1.1915 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9769 - accuracy: 0.7357 - val_loss: 1.0391 - val_accuracy: 0.6987\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9037 - accuracy: 0.7353 - val_loss: 1.0216 - val_accuracy: 0.7147\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8287 - accuracy: 0.7707 - val_loss: 0.9065 - val_accuracy: 0.7532\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7640 - accuracy: 0.7911 - val_loss: 0.8757 - val_accuracy: 0.7724\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.7402 - accuracy: 0.8072 - val_loss: 0.7865 - val_accuracy: 0.7724\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6972 - accuracy: 0.8075 - val_loss: 0.8114 - val_accuracy: 0.7372\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.6759 - accuracy: 0.8140 - val_loss: 0.7701 - val_accuracy: 0.7724\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6189 - accuracy: 0.8284 - val_loss: 0.7012 - val_accuracy: 0.8173\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6308 - accuracy: 0.8128 - val_loss: 0.7831 - val_accuracy: 0.7628\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5813 - accuracy: 0.8299 - val_loss: 0.6793 - val_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5660 - accuracy: 0.8462 - val_loss: 0.7442 - val_accuracy: 0.7885\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5461 - accuracy: 0.8369 - val_loss: 0.6913 - val_accuracy: 0.7788\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5249 - accuracy: 0.8431 - val_loss: 0.6073 - val_accuracy: 0.7949\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4867 - accuracy: 0.8490 - val_loss: 0.6308 - val_accuracy: 0.7949\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4776 - accuracy: 0.8657 - val_loss: 0.6003 - val_accuracy: 0.8109\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4402 - accuracy: 0.8693 - val_loss: 0.6233 - val_accuracy: 0.7917\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.4408 - accuracy: 0.8787 - val_loss: 0.6110 - val_accuracy: 0.8141\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4502 - accuracy: 0.8718 - val_loss: 0.6064 - val_accuracy: 0.8109\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4232 - accuracy: 0.8809 - val_loss: 0.5499 - val_accuracy: 0.8173\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3909 - accuracy: 0.8902 - val_loss: 0.5733 - val_accuracy: 0.8141\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3900 - accuracy: 0.8891 - val_loss: 0.5678 - val_accuracy: 0.8077\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3655 - accuracy: 0.8946 - val_loss: 0.5725 - val_accuracy: 0.8237\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3957 - accuracy: 0.8890 - val_loss: 0.5751 - val_accuracy: 0.8462\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3436 - accuracy: 0.9013 - val_loss: 0.4957 - val_accuracy: 0.8526\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.3031 - accuracy: 0.9152 - val_loss: 0.4978 - val_accuracy: 0.8558\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3418 - accuracy: 0.9047 - val_loss: 0.4924 - val_accuracy: 0.8462\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.3217 - accuracy: 0.9178 - val_loss: 0.4836 - val_accuracy: 0.8397\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.3091 - accuracy: 0.9169 - val_loss: 0.4977 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.3247 - accuracy: 0.9068 - val_loss: 0.4932 - val_accuracy: 0.8590\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.3113 - accuracy: 0.9080 - val_loss: 0.4774 - val_accuracy: 0.8686\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.2873 - accuracy: 0.9183 - val_loss: 0.4959 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.2798 - accuracy: 0.9223 - val_loss: 0.4782 - val_accuracy: 0.8494\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 3s 58ms/step - loss: 0.2969 - accuracy: 0.9200 - val_loss: 0.5915 - val_accuracy: 0.8109\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.2760 - accuracy: 0.9181 - val_loss: 0.4794 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 56ms/step - loss: 0.2555 - accuracy: 0.9315 - val_loss: 0.4571 - val_accuracy: 0.8462\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2615 - accuracy: 0.9333 - val_loss: 0.4409 - val_accuracy: 0.8622\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2580 - accuracy: 0.9370 - val_loss: 0.4520 - val_accuracy: 0.8494\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2706 - accuracy: 0.9350 - val_loss: 0.4612 - val_accuracy: 0.8622\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2527 - accuracy: 0.9273 - val_loss: 0.4391 - val_accuracy: 0.8622\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2359 - accuracy: 0.9430 - val_loss: 0.4467 - val_accuracy: 0.8526\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2462 - accuracy: 0.9355 - val_loss: 0.4401 - val_accuracy: 0.8686\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2644 - accuracy: 0.9313 - val_loss: 0.4499 - val_accuracy: 0.8494\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2383 - accuracy: 0.9374 - val_loss: 0.4422 - val_accuracy: 0.8654\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2225 - accuracy: 0.9506 - val_loss: 0.4348 - val_accuracy: 0.8526\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2203 - accuracy: 0.9482 - val_loss: 0.4379 - val_accuracy: 0.8590\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2336 - accuracy: 0.9426 - val_loss: 0.4442 - val_accuracy: 0.8590\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2381 - accuracy: 0.9291 - val_loss: 0.4344 - val_accuracy: 0.8622\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2319 - accuracy: 0.9391 - val_loss: 0.4321 - val_accuracy: 0.8526\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2212 - accuracy: 0.9454 - val_loss: 0.4351 - val_accuracy: 0.8494\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2301 - accuracy: 0.9361 - val_loss: 0.4270 - val_accuracy: 0.8686\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2289 - accuracy: 0.9415 - val_loss: 0.4294 - val_accuracy: 0.8558\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2254 - accuracy: 0.9351 - val_loss: 0.4333 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2170 - accuracy: 0.9445 - val_loss: 0.4370 - val_accuracy: 0.8558\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2239 - accuracy: 0.9468 - val_loss: 0.4246 - val_accuracy: 0.8558\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2178 - accuracy: 0.9416 - val_loss: 0.4321 - val_accuracy: 0.8462\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2094 - accuracy: 0.9498 - val_loss: 0.4234 - val_accuracy: 0.8686\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2137 - accuracy: 0.9481 - val_loss: 0.4391 - val_accuracy: 0.8526\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2296 - accuracy: 0.9456 - val_loss: 0.4237 - val_accuracy: 0.8590\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2074 - accuracy: 0.9504 - val_loss: 0.4292 - val_accuracy: 0.8590\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 0.4322 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2036 - accuracy: 0.9539 - val_loss: 0.4273 - val_accuracy: 0.8686\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2129 - accuracy: 0.9496 - val_loss: 0.4273 - val_accuracy: 0.8622\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2061 - accuracy: 0.9498 - val_loss: 0.4280 - val_accuracy: 0.8558\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1995 - accuracy: 0.9491 - val_loss: 0.4240 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8686\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4234 - accuracy: 0.8686\n",
      "--------------------Fold_9--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 4s 62ms/step - loss: 3.3604 - accuracy: 0.3415 - val_loss: 3.2233 - val_accuracy: 0.3301\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 55ms/step - loss: 1.9556 - accuracy: 0.5476 - val_loss: 1.9052 - val_accuracy: 0.5385\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 1.6984 - accuracy: 0.5898 - val_loss: 1.9132 - val_accuracy: 0.5609\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5684 - accuracy: 0.6103 - val_loss: 1.7508 - val_accuracy: 0.5705\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3796 - accuracy: 0.6498 - val_loss: 1.5880 - val_accuracy: 0.5897\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2447 - accuracy: 0.6788 - val_loss: 1.3694 - val_accuracy: 0.6154\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.1414 - accuracy: 0.7006 - val_loss: 1.2754 - val_accuracy: 0.6474\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0466 - accuracy: 0.7189 - val_loss: 1.2456 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9686 - accuracy: 0.7316 - val_loss: 1.1440 - val_accuracy: 0.6891\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9016 - accuracy: 0.7550 - val_loss: 0.9499 - val_accuracy: 0.7147\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8312 - accuracy: 0.7663 - val_loss: 0.9424 - val_accuracy: 0.7147\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8211 - accuracy: 0.7696 - val_loss: 0.8755 - val_accuracy: 0.7436\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7764 - accuracy: 0.7851 - val_loss: 0.9005 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6961 - accuracy: 0.7999 - val_loss: 0.8821 - val_accuracy: 0.7468\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7087 - accuracy: 0.8025 - val_loss: 0.7959 - val_accuracy: 0.7724\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6458 - accuracy: 0.8106 - val_loss: 0.7999 - val_accuracy: 0.7340\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6326 - accuracy: 0.8149 - val_loss: 0.7276 - val_accuracy: 0.7756\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5987 - accuracy: 0.8315 - val_loss: 0.7325 - val_accuracy: 0.8077\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5305 - accuracy: 0.8557 - val_loss: 0.7445 - val_accuracy: 0.7788\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5343 - accuracy: 0.8449 - val_loss: 0.6841 - val_accuracy: 0.8013\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5378 - accuracy: 0.8573 - val_loss: 0.7148 - val_accuracy: 0.7532\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5340 - accuracy: 0.8449 - val_loss: 0.6323 - val_accuracy: 0.8045\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4625 - accuracy: 0.8679 - val_loss: 0.6242 - val_accuracy: 0.8237\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4762 - accuracy: 0.8529 - val_loss: 0.5899 - val_accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4813 - accuracy: 0.8603 - val_loss: 0.6317 - val_accuracy: 0.7917\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4154 - accuracy: 0.8905 - val_loss: 0.5931 - val_accuracy: 0.8077\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4095 - accuracy: 0.8812 - val_loss: 0.6450 - val_accuracy: 0.8013\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4227 - accuracy: 0.8759 - val_loss: 0.5568 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3793 - accuracy: 0.8869 - val_loss: 0.6237 - val_accuracy: 0.8109\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3817 - accuracy: 0.8954 - val_loss: 0.5989 - val_accuracy: 0.8077\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3967 - accuracy: 0.8861 - val_loss: 0.6322 - val_accuracy: 0.7853\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.3703 - accuracy: 0.8953 - val_loss: 0.5890 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.3479 - accuracy: 0.9014 - val_loss: 0.5435 - val_accuracy: 0.8109\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3339 - accuracy: 0.9045 - val_loss: 0.5321 - val_accuracy: 0.8365\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3111 - accuracy: 0.9188 - val_loss: 0.4897 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3219 - accuracy: 0.9136 - val_loss: 0.5008 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2858 - accuracy: 0.9201 - val_loss: 0.4863 - val_accuracy: 0.8237\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2954 - accuracy: 0.9234 - val_loss: 0.4884 - val_accuracy: 0.8526\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2924 - accuracy: 0.9227 - val_loss: 0.4845 - val_accuracy: 0.8494\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2908 - accuracy: 0.9231 - val_loss: 0.5342 - val_accuracy: 0.8365\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3011 - accuracy: 0.9209 - val_loss: 0.5006 - val_accuracy: 0.8301\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2657 - accuracy: 0.9219 - val_loss: 0.4757 - val_accuracy: 0.8365\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2975 - accuracy: 0.9235 - val_loss: 0.4760 - val_accuracy: 0.8429\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2640 - accuracy: 0.9284 - val_loss: 0.5100 - val_accuracy: 0.8173\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2893 - accuracy: 0.9226 - val_loss: 0.5060 - val_accuracy: 0.8269\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2563 - accuracy: 0.9339 - val_loss: 0.4983 - val_accuracy: 0.8237\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2352 - accuracy: 0.9387 - val_loss: 0.4677 - val_accuracy: 0.8397\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2397 - accuracy: 0.9354 - val_loss: 0.4821 - val_accuracy: 0.8205\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.2354 - accuracy: 0.9404 - val_loss: 0.4669 - val_accuracy: 0.8558\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 53ms/step - loss: 0.2294 - accuracy: 0.9386 - val_loss: 0.4793 - val_accuracy: 0.8333\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 3s 60ms/step - loss: 0.2371 - accuracy: 0.9396 - val_loss: 0.4843 - val_accuracy: 0.8365\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2476 - accuracy: 0.9364 - val_loss: 0.4736 - val_accuracy: 0.8301\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2274 - accuracy: 0.9392 - val_loss: 0.4946 - val_accuracy: 0.8269\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2183 - accuracy: 0.9415 - val_loss: 0.4646 - val_accuracy: 0.8397\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2434 - accuracy: 0.9333 - val_loss: 0.4599 - val_accuracy: 0.8397\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2127 - accuracy: 0.9455 - val_loss: 0.4572 - val_accuracy: 0.8429\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2234 - accuracy: 0.9335 - val_loss: 0.4535 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2272 - accuracy: 0.9417 - val_loss: 0.4502 - val_accuracy: 0.8365\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2187 - accuracy: 0.9470 - val_loss: 0.4517 - val_accuracy: 0.8397\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2008 - accuracy: 0.9487 - val_loss: 0.4554 - val_accuracy: 0.8462\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2173 - accuracy: 0.9452 - val_loss: 0.4540 - val_accuracy: 0.8429\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2122 - accuracy: 0.9475 - val_loss: 0.4436 - val_accuracy: 0.8397\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2091 - accuracy: 0.9436 - val_loss: 0.4624 - val_accuracy: 0.8269\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2002 - accuracy: 0.9513 - val_loss: 0.4663 - val_accuracy: 0.8429\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2126 - accuracy: 0.9489 - val_loss: 0.4413 - val_accuracy: 0.8397\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2054 - accuracy: 0.9498 - val_loss: 0.4437 - val_accuracy: 0.8397\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2164 - accuracy: 0.9387 - val_loss: 0.4434 - val_accuracy: 0.8397\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2340 - accuracy: 0.9365 - val_loss: 0.4557 - val_accuracy: 0.8462\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1961 - accuracy: 0.9514 - val_loss: 0.4688 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.2010 - accuracy: 0.9478 - val_loss: 0.4448 - val_accuracy: 0.8462\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1948 - accuracy: 0.9448 - val_loss: 0.4397 - val_accuracy: 0.8397\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2003 - accuracy: 0.9514 - val_loss: 0.4445 - val_accuracy: 0.8462\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2182 - accuracy: 0.9435 - val_loss: 0.4487 - val_accuracy: 0.8397\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1986 - accuracy: 0.9486 - val_loss: 0.4431 - val_accuracy: 0.8397\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2078 - accuracy: 0.9480 - val_loss: 0.4449 - val_accuracy: 0.8365\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.2016 - accuracy: 0.9474 - val_loss: 0.4490 - val_accuracy: 0.8462\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1935 - accuracy: 0.9471 - val_loss: 0.4482 - val_accuracy: 0.8494\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 2s 51ms/step - loss: 0.1945 - accuracy: 0.9568 - val_loss: 0.4447 - val_accuracy: 0.8397\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 2s 54ms/step - loss: 0.1873 - accuracy: 0.9561 - val_loss: 0.4402 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.8397\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.8397\n",
      "--------------------Fold_10--------------------\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 53ms/step - loss: 3.4042 - accuracy: 0.3261 - val_loss: 3.1749 - val_accuracy: 0.3173\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 2.0163 - accuracy: 0.5444 - val_loss: 1.9114 - val_accuracy: 0.5513\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.7579 - accuracy: 0.5710 - val_loss: 1.8172 - val_accuracy: 0.5641\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.5243 - accuracy: 0.6207 - val_loss: 1.7702 - val_accuracy: 0.5897\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.3683 - accuracy: 0.6550 - val_loss: 1.5276 - val_accuracy: 0.6442\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2497 - accuracy: 0.6842 - val_loss: 1.3745 - val_accuracy: 0.6474\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.2053 - accuracy: 0.6853 - val_loss: 1.2776 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 1.0429 - accuracy: 0.7155 - val_loss: 1.1315 - val_accuracy: 0.7019\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.9870 - accuracy: 0.7364 - val_loss: 0.9979 - val_accuracy: 0.7276\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8939 - accuracy: 0.7581 - val_loss: 0.9506 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.8760 - accuracy: 0.7577 - val_loss: 0.8973 - val_accuracy: 0.7468\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7878 - accuracy: 0.7838 - val_loss: 0.8752 - val_accuracy: 0.7756\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7573 - accuracy: 0.7938 - val_loss: 0.8492 - val_accuracy: 0.7436\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.7563 - accuracy: 0.7782 - val_loss: 0.8293 - val_accuracy: 0.7628\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6863 - accuracy: 0.8059 - val_loss: 0.7961 - val_accuracy: 0.7724\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6630 - accuracy: 0.8050 - val_loss: 0.7488 - val_accuracy: 0.7981\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.6254 - accuracy: 0.8251 - val_loss: 0.7088 - val_accuracy: 0.8077\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5817 - accuracy: 0.8304 - val_loss: 0.7011 - val_accuracy: 0.7917\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5855 - accuracy: 0.8287 - val_loss: 0.6963 - val_accuracy: 0.7885\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5626 - accuracy: 0.8355 - val_loss: 0.6994 - val_accuracy: 0.8173\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5323 - accuracy: 0.8454 - val_loss: 0.6130 - val_accuracy: 0.8013\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5042 - accuracy: 0.8509 - val_loss: 0.9155 - val_accuracy: 0.7724\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5036 - accuracy: 0.8489 - val_loss: 0.5759 - val_accuracy: 0.8237\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4613 - accuracy: 0.8669 - val_loss: 0.6163 - val_accuracy: 0.8237\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4619 - accuracy: 0.8725 - val_loss: 0.5877 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4366 - accuracy: 0.8757 - val_loss: 0.6348 - val_accuracy: 0.8269\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4521 - accuracy: 0.8687 - val_loss: 0.5931 - val_accuracy: 0.8173\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.4239 - accuracy: 0.8775 - val_loss: 0.5290 - val_accuracy: 0.8365\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3581 - accuracy: 0.9083 - val_loss: 0.5518 - val_accuracy: 0.8269\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3624 - accuracy: 0.8950 - val_loss: 0.5250 - val_accuracy: 0.8429\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3535 - accuracy: 0.8975 - val_loss: 0.5338 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3562 - accuracy: 0.9096 - val_loss: 0.5345 - val_accuracy: 0.8173\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3622 - accuracy: 0.8993 - val_loss: 0.5002 - val_accuracy: 0.8526\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3295 - accuracy: 0.9094 - val_loss: 0.5168 - val_accuracy: 0.8269\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3250 - accuracy: 0.9127 - val_loss: 0.5325 - val_accuracy: 0.8365\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3401 - accuracy: 0.9083 - val_loss: 0.5241 - val_accuracy: 0.8269\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3316 - accuracy: 0.9167 - val_loss: 0.5054 - val_accuracy: 0.8301\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3148 - accuracy: 0.9056 - val_loss: 0.4720 - val_accuracy: 0.8494\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3107 - accuracy: 0.9185 - val_loss: 0.4808 - val_accuracy: 0.8397\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3008 - accuracy: 0.9262 - val_loss: 0.4713 - val_accuracy: 0.8429\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2944 - accuracy: 0.9337 - val_loss: 0.4825 - val_accuracy: 0.8462\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2910 - accuracy: 0.9200 - val_loss: 0.4860 - val_accuracy: 0.8429\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2999 - accuracy: 0.9263 - val_loss: 0.4644 - val_accuracy: 0.8494\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2967 - accuracy: 0.9216 - val_loss: 0.4875 - val_accuracy: 0.8429\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2813 - accuracy: 0.9210 - val_loss: 0.4673 - val_accuracy: 0.8494\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2647 - accuracy: 0.9309 - val_loss: 0.4786 - val_accuracy: 0.8365\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2865 - accuracy: 0.9271 - val_loss: 0.4668 - val_accuracy: 0.8558\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2537 - accuracy: 0.9367 - val_loss: 0.4620 - val_accuracy: 0.8558\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2525 - accuracy: 0.9409 - val_loss: 0.4651 - val_accuracy: 0.8429\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2533 - accuracy: 0.9332 - val_loss: 0.4586 - val_accuracy: 0.8526\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2579 - accuracy: 0.9355 - val_loss: 0.4683 - val_accuracy: 0.8494\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2601 - accuracy: 0.9347 - val_loss: 0.4660 - val_accuracy: 0.8429\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2636 - accuracy: 0.9343 - val_loss: 0.4623 - val_accuracy: 0.8494\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2555 - accuracy: 0.9361 - val_loss: 0.4581 - val_accuracy: 0.8526\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2611 - accuracy: 0.9347 - val_loss: 0.4537 - val_accuracy: 0.8526\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2652 - accuracy: 0.9367 - val_loss: 0.4636 - val_accuracy: 0.8558\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2499 - accuracy: 0.9379 - val_loss: 0.4502 - val_accuracy: 0.8526\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2684 - accuracy: 0.9340 - val_loss: 0.4633 - val_accuracy: 0.8526\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2531 - accuracy: 0.9341 - val_loss: 0.4491 - val_accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2454 - accuracy: 0.9388 - val_loss: 0.4556 - val_accuracy: 0.8590\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2602 - accuracy: 0.9293 - val_loss: 0.4439 - val_accuracy: 0.8526\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2579 - accuracy: 0.9341 - val_loss: 0.4495 - val_accuracy: 0.8558\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2392 - accuracy: 0.9416 - val_loss: 0.4496 - val_accuracy: 0.8558\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2493 - accuracy: 0.9344 - val_loss: 0.4634 - val_accuracy: 0.8494\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2415 - accuracy: 0.9380 - val_loss: 0.4511 - val_accuracy: 0.8526\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2529 - accuracy: 0.9362 - val_loss: 0.4514 - val_accuracy: 0.8526\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2460 - accuracy: 0.9378 - val_loss: 0.4474 - val_accuracy: 0.8526\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2369 - accuracy: 0.9417 - val_loss: 0.4567 - val_accuracy: 0.8494\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2508 - accuracy: 0.9408 - val_loss: 0.4503 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.8526\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.8526\n",
      "\n",
      "K-fold cross validation Auc: ['0.8498', '0.8498', '0.8818', '0.8243', '0.8594', '0.8494', '0.8526', '0.8686', '0.8397', '0.8526']\n",
      "\n",
      "K-fold cross validation loss: ['0.5330', '0.4526', '0.4037', '0.6105', '0.4526', '0.5628', '0.4766', '0.4234', '0.4397', '0.4439']\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, random_state = 2021, shuffle = True)\n",
    "reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n",
    "es =EarlyStopping(monitor='val_loss', patience=8, mode='min')\n",
    "\n",
    "accuracy = []\n",
    "losss=[]\n",
    "models=[]\n",
    "\n",
    "for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n",
    "    mc = ModelCheckpoint(f'./open/cv_study{i + 1}.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)\n",
    "    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n",
    "    model = cnn_model((600,18),61)\n",
    "    history = model.fit(X[train], y[train], epochs = 100, validation_data= (X[validation], y[validation]), \n",
    "                        verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n",
    "    model.load_weights(f'./open/cv_study{i + 1}.h5')\n",
    "    \n",
    "    k_accuracy = '%.4f' % (model.evaluate(X[validation], y[validation])[1])\n",
    "    k_loss = '%.4f' % (model.evaluate(X[validation], y[validation])[0])\n",
    "    \n",
    "    accuracy.append(k_accuracy)\n",
    "    losss.append(k_loss)\n",
    "    models.append(model)\n",
    "\n",
    "print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation loss: {}'.format(losss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(782, 600, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "test_X=np.array(test_sc.iloc[:,2:]).reshape(782, 600, -1)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[4.3955456e-06, 1.0051062e-06, 3.4406258e-07, ..., 4.3151681e-03,\n",
       "        5.7393358e-06, 3.1050745e-06],\n",
       "       [5.7655328e-04, 2.7663316e-05, 5.3001568e-05, ..., 3.3672854e-06,\n",
       "        2.5347626e-05, 1.6828923e-05],\n",
       "       [6.7229557e-04, 2.6267871e-02, 4.5714414e-06, ..., 3.5736561e-04,\n",
       "        7.2013624e-03, 3.5649729e-03],\n",
       "       ...,\n",
       "       [4.3212710e-04, 5.0058084e-06, 5.8348714e-06, ..., 1.5295202e-05,\n",
       "        7.4118151e-07, 1.2497038e-03],\n",
       "       [6.0677394e-06, 6.0142553e-04, 4.4212410e-07, ..., 1.2092964e-07,\n",
       "        3.8138357e-06, 1.2453638e-08],\n",
       "       [7.6904784e-05, 4.1955818e-06, 8.4090186e-07, ..., 2.3960423e-04,\n",
       "        1.2979629e-06, 2.9697843e-04]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "preds = []\n",
    "for model in models:\n",
    "    pred = model.predict(test_X)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       id         0         1             2             3             4  \\\n",
       "0    3125  0.000004  0.000001  3.440626e-07  1.768032e-08  1.430821e-04   \n",
       "1    3126  0.000577  0.000028  5.300157e-05  1.959058e-03  5.176046e-05   \n",
       "2    3127  0.000672  0.026268  4.571441e-06  2.903764e-06  3.132365e-05   \n",
       "3    3128  0.000444  0.000009  9.982874e-05  2.026598e-04  5.966680e-06   \n",
       "4    3129  0.001811  0.000027  1.599152e-06  5.231936e-04  4.356049e-04   \n",
       "..    ...       ...       ...           ...           ...           ...   \n",
       "777  3902  0.003376  0.000024  9.289932e-07  2.241921e-04  6.610556e-04   \n",
       "778  3903  0.000046  0.000003  2.171766e-07  2.634886e-04  5.808211e-05   \n",
       "779  3904  0.000432  0.000005  5.834871e-06  2.168282e-04  1.245494e-05   \n",
       "780  3905  0.000006  0.000601  4.421241e-07  2.577478e-09  1.550255e-08   \n",
       "781  3906  0.000077  0.000004  8.409019e-07  1.342619e-04  8.561942e-05   \n",
       "\n",
       "                5             6         7             8         9  \\\n",
       "0    5.899136e-07  1.405213e-04  0.000013  5.970440e-08  0.007118   \n",
       "1    5.458228e-04  6.400153e-06  0.000076  3.841904e-06  0.000022   \n",
       "2    3.466806e-04  3.492374e-02  0.000149  2.000439e-05  0.000369   \n",
       "3    4.726128e-05  4.240780e-06  0.000141  1.050581e-03  0.000019   \n",
       "4    3.635793e-05  9.546840e-07  0.000003  1.444059e-05  0.000040   \n",
       "..            ...           ...       ...           ...       ...   \n",
       "777  7.387674e-05  5.232951e-07  0.000005  4.411094e-05  0.000009   \n",
       "778  2.498243e-05  1.181050e-08  0.000001  1.973592e-07  0.000001   \n",
       "779  5.532837e-05  2.084059e-06  0.000017  1.737914e-05  0.000020   \n",
       "780  4.920408e-08  8.814055e-03  0.000012  2.349413e-08  0.000008   \n",
       "781  5.342241e-05  9.995349e-08  0.000005  2.060849e-07  0.000003   \n",
       "\n",
       "               10            11            12            13            14  \\\n",
       "0    6.998050e-02  4.721001e-01  4.764451e-04  4.223833e-01  1.692203e-03   \n",
       "1    1.020382e-05  6.470441e-07  6.671296e-08  1.219125e-06  1.682519e-06   \n",
       "2    1.338044e-03  3.982928e-04  5.649381e-05  4.395702e-03  1.394045e-02   \n",
       "3    2.445121e-04  7.195385e-05  3.480275e-06  2.057023e-06  2.487789e-05   \n",
       "4    2.423781e-05  6.675769e-06  8.358064e-07  4.521470e-07  2.454368e-05   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  1.146871e-05  5.468364e-07  1.348126e-07  2.086083e-07  4.269572e-06   \n",
       "778  1.834327e-07  3.506831e-08  4.530533e-09  1.919050e-08  1.093814e-07   \n",
       "779  3.347022e-05  4.028117e-06  3.079397e-07  3.438513e-07  1.676546e-05   \n",
       "780  5.321275e-06  2.676131e-05  2.608368e-08  4.612240e-04  5.015236e-07   \n",
       "781  1.188621e-05  2.228837e-07  5.417503e-08  3.117734e-07  9.369535e-06   \n",
       "\n",
       "               15            16            17            18            19  \\\n",
       "0    8.108493e-06  1.865974e-06  2.750837e-07  6.628549e-07  5.420466e-06   \n",
       "1    2.643538e-04  8.169426e-06  1.423647e-05  1.677734e-05  3.802030e-06   \n",
       "2    8.687613e-04  1.727450e-04  4.597991e-04  2.301811e-05  2.904742e-04   \n",
       "3    2.828537e-04  3.279070e-07  3.549706e-06  2.182547e-06  1.598718e-06   \n",
       "4    4.665540e-04  9.037330e-06  1.200840e-05  1.359197e-04  2.191336e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  5.250274e-04  1.108902e-05  8.549371e-06  2.838518e-04  2.184845e-06   \n",
       "778  1.139006e-04  1.085911e-05  2.973405e-06  5.885158e-05  4.363570e-07   \n",
       "779  1.481532e-04  3.614811e-07  8.481842e-07  2.230498e-06  5.927222e-07   \n",
       "780  1.233775e-07  5.471856e-06  5.796545e-07  2.409827e-09  3.810382e-07   \n",
       "781  7.194764e-05  5.408833e-06  1.244227e-06  1.200303e-05  8.673358e-07   \n",
       "\n",
       "               20            21            22        23  ...            36  \\\n",
       "0    3.000905e-06  2.785819e-06  1.190323e-06  0.011513  ...  8.268285e-04   \n",
       "1    2.032817e-05  1.472189e-04  3.454946e-03  0.000140  ...  1.630262e-04   \n",
       "2    3.732721e-04  8.402640e-05  1.085599e-07  0.000250  ...  1.453728e-03   \n",
       "3    3.212181e-06  6.472810e-05  3.767232e-05  0.000081  ...  2.424678e-04   \n",
       "4    4.354409e-06  7.573354e-06  1.892100e-04  0.000011  ...  1.491847e-05   \n",
       "..            ...           ...           ...       ...  ...           ...   \n",
       "777  2.186964e-06  3.047839e-06  2.014188e-04  0.000004  ...  5.442039e-06   \n",
       "778  1.138996e-06  7.555505e-07  9.977297e-04  0.000002  ...  2.731617e-07   \n",
       "779  2.632754e-06  3.697830e-05  8.000265e-05  0.000016  ...  1.018092e-04   \n",
       "780  1.035291e-07  5.019211e-06  9.058112e-09  0.000006  ...  3.239656e-05   \n",
       "781  1.331399e-06  1.980636e-06  8.965555e-04  0.000014  ...  3.372931e-06   \n",
       "\n",
       "               37            38            39            40            41  \\\n",
       "0    6.636359e-04  1.423408e-04  1.831121e-05  7.080535e-08  1.448755e-07   \n",
       "1    3.529139e-06  3.150341e-06  7.636694e-08  4.029530e-04  3.600028e-04   \n",
       "2    8.734466e-02  8.290728e-03  1.459409e-04  3.829252e-04  1.235150e-04   \n",
       "3    1.056190e-06  5.237694e-05  9.614967e-07  7.052824e-06  4.694936e-06   \n",
       "4    2.577658e-07  2.068980e-05  1.917756e-06  9.711699e-07  6.547080e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  1.301118e-07  1.054748e-05  1.026104e-07  3.990949e-06  7.954625e-06   \n",
       "778  1.333596e-08  4.436761e-07  2.557141e-09  4.947949e-06  2.176467e-05   \n",
       "779  2.778946e-07  7.045038e-06  3.608197e-07  1.565169e-06  2.798694e-06   \n",
       "780  9.890268e-01  1.599520e-06  1.074810e-07  6.554482e-06  1.289670e-07   \n",
       "781  8.484487e-08  6.479303e-06  1.596174e-08  4.953384e-06  3.489677e-05   \n",
       "\n",
       "           42        43            44            45            46  \\\n",
       "0    0.000945  0.000090  3.519620e-05  1.346798e-03  1.241451e-05   \n",
       "1    0.000010  0.000009  8.909231e-07  1.910726e-06  1.017850e-05   \n",
       "2    0.028401  0.231138  1.160992e-02  4.729814e-01  9.531206e-04   \n",
       "3    0.000014  0.000024  1.516358e-05  2.212631e-05  7.816576e-06   \n",
       "4    0.000040  0.000031  7.696641e-08  5.184464e-07  1.530681e-05   \n",
       "..        ...       ...           ...           ...           ...   \n",
       "777  0.000008  0.000003  1.609850e-07  4.242834e-07  1.483794e-05   \n",
       "778  0.000004  0.000001  4.065248e-09  1.587645e-08  1.179277e-06   \n",
       "779  0.000004  0.000011  4.437944e-07  1.779633e-06  1.530016e-06   \n",
       "780  0.000022  0.000015  5.835751e-05  6.031017e-04  7.186250e-07   \n",
       "781  0.000048  0.000009  6.950701e-08  2.413539e-07  1.531095e-06   \n",
       "\n",
       "               47            48            49            50            51  \\\n",
       "0    1.571495e-07  4.367356e-06  3.727425e-06  3.882373e-08  7.158775e-04   \n",
       "1    3.355664e-05  1.786967e-04  2.073932e-03  7.157866e-04  6.616122e-06   \n",
       "2    7.486226e-04  1.829613e-03  2.491417e-03  7.356184e-07  9.112000e-05   \n",
       "3    3.818717e-05  2.224833e-03  6.101608e-03  8.398696e-04  1.489779e-04   \n",
       "4    2.533567e-06  4.491681e-04  7.765405e-04  4.753325e-04  9.975126e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  2.448846e-06  2.470944e-04  4.117446e-04  7.730624e-04  6.550279e-07   \n",
       "778  1.595002e-07  1.565475e-05  4.792718e-05  3.617416e-05  2.020144e-07   \n",
       "779  1.453326e-05  6.313912e-04  1.967291e-03  1.213715e-04  1.171371e-05   \n",
       "780  1.242279e-04  5.051617e-07  7.716503e-07  2.039447e-09  1.477869e-06   \n",
       "781  6.023533e-07  4.895016e-05  1.692420e-04  1.069355e-04  2.124048e-07   \n",
       "\n",
       "               52            53            54            55            56  \\\n",
       "0    1.799114e-04  3.515418e-06  5.159307e-06  1.093319e-07  2.205167e-05   \n",
       "1    6.415556e-08  1.005095e-04  2.985222e-04  9.486639e-05  1.273018e-05   \n",
       "2    2.348217e-05  1.185400e-06  9.130159e-04  8.107526e-07  1.915725e-03   \n",
       "3    9.851968e-06  2.031352e-05  2.558382e-05  3.767787e-05  1.848217e-06   \n",
       "4    8.568231e-07  1.432784e-05  2.281642e-06  4.715525e-06  1.309887e-06   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  7.858764e-08  3.598512e-06  5.697138e-07  1.385776e-06  1.042821e-06   \n",
       "778  2.688058e-09  5.081118e-06  3.864673e-07  1.108734e-06  6.860322e-07   \n",
       "779  5.068287e-07  1.091375e-05  1.502929e-05  1.100640e-05  6.298472e-07   \n",
       "780  2.508699e-08  1.340853e-07  2.458059e-05  3.287898e-08  2.375942e-05   \n",
       "781  2.577672e-08  1.721582e-06  1.011961e-06  4.961008e-07  3.626475e-07   \n",
       "\n",
       "               57            58            59            60  \n",
       "0    3.069901e-09  4.315168e-03  5.739336e-06  3.105074e-06  \n",
       "1    1.075205e-04  3.367285e-06  2.534763e-05  1.682892e-05  \n",
       "2    6.510400e-08  3.573656e-04  7.201362e-03  3.564973e-03  \n",
       "3    3.832962e-05  1.474924e-05  3.222499e-06  6.864996e-03  \n",
       "4    1.383369e-03  5.538989e-05  2.613220e-06  5.682869e-03  \n",
       "..            ...           ...           ...           ...  \n",
       "777  2.662610e-03  1.546706e-05  3.246937e-06  2.529361e-03  \n",
       "778  1.589115e-03  2.275958e-06  4.922045e-07  3.214272e-05  \n",
       "779  6.372209e-05  1.529520e-05  7.411815e-07  1.249704e-03  \n",
       "780  3.813196e-11  1.209296e-07  3.813836e-06  1.245364e-08  \n",
       "781  3.123985e-03  2.396042e-04  1.297963e-06  2.969784e-04  \n",
       "\n",
       "[782 rows x 62 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>...</th>\n      <th>36</th>\n      <th>37</th>\n      <th>38</th>\n      <th>39</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n      <th>58</th>\n      <th>59</th>\n      <th>60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3125</td>\n      <td>0.000004</td>\n      <td>0.000001</td>\n      <td>3.440626e-07</td>\n      <td>1.768032e-08</td>\n      <td>1.430821e-04</td>\n      <td>5.899136e-07</td>\n      <td>1.405213e-04</td>\n      <td>0.000013</td>\n      <td>5.970440e-08</td>\n      <td>0.007118</td>\n      <td>6.998050e-02</td>\n      <td>4.721001e-01</td>\n      <td>4.764451e-04</td>\n      <td>4.223833e-01</td>\n      <td>1.692203e-03</td>\n      <td>8.108493e-06</td>\n      <td>1.865974e-06</td>\n      <td>2.750837e-07</td>\n      <td>6.628549e-07</td>\n      <td>5.420466e-06</td>\n      <td>3.000905e-06</td>\n      <td>2.785819e-06</td>\n      <td>1.190323e-06</td>\n      <td>0.011513</td>\n      <td>...</td>\n      <td>8.268285e-04</td>\n      <td>6.636359e-04</td>\n      <td>1.423408e-04</td>\n      <td>1.831121e-05</td>\n      <td>7.080535e-08</td>\n      <td>1.448755e-07</td>\n      <td>0.000945</td>\n      <td>0.000090</td>\n      <td>3.519620e-05</td>\n      <td>1.346798e-03</td>\n      <td>1.241451e-05</td>\n      <td>1.571495e-07</td>\n      <td>4.367356e-06</td>\n      <td>3.727425e-06</td>\n      <td>3.882373e-08</td>\n      <td>7.158775e-04</td>\n      <td>1.799114e-04</td>\n      <td>3.515418e-06</td>\n      <td>5.159307e-06</td>\n      <td>1.093319e-07</td>\n      <td>2.205167e-05</td>\n      <td>3.069901e-09</td>\n      <td>4.315168e-03</td>\n      <td>5.739336e-06</td>\n      <td>3.105074e-06</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3126</td>\n      <td>0.000577</td>\n      <td>0.000028</td>\n      <td>5.300157e-05</td>\n      <td>1.959058e-03</td>\n      <td>5.176046e-05</td>\n      <td>5.458228e-04</td>\n      <td>6.400153e-06</td>\n      <td>0.000076</td>\n      <td>3.841904e-06</td>\n      <td>0.000022</td>\n      <td>1.020382e-05</td>\n      <td>6.470441e-07</td>\n      <td>6.671296e-08</td>\n      <td>1.219125e-06</td>\n      <td>1.682519e-06</td>\n      <td>2.643538e-04</td>\n      <td>8.169426e-06</td>\n      <td>1.423647e-05</td>\n      <td>1.677734e-05</td>\n      <td>3.802030e-06</td>\n      <td>2.032817e-05</td>\n      <td>1.472189e-04</td>\n      <td>3.454946e-03</td>\n      <td>0.000140</td>\n      <td>...</td>\n      <td>1.630262e-04</td>\n      <td>3.529139e-06</td>\n      <td>3.150341e-06</td>\n      <td>7.636694e-08</td>\n      <td>4.029530e-04</td>\n      <td>3.600028e-04</td>\n      <td>0.000010</td>\n      <td>0.000009</td>\n      <td>8.909231e-07</td>\n      <td>1.910726e-06</td>\n      <td>1.017850e-05</td>\n      <td>3.355664e-05</td>\n      <td>1.786967e-04</td>\n      <td>2.073932e-03</td>\n      <td>7.157866e-04</td>\n      <td>6.616122e-06</td>\n      <td>6.415556e-08</td>\n      <td>1.005095e-04</td>\n      <td>2.985222e-04</td>\n      <td>9.486639e-05</td>\n      <td>1.273018e-05</td>\n      <td>1.075205e-04</td>\n      <td>3.367285e-06</td>\n      <td>2.534763e-05</td>\n      <td>1.682892e-05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3127</td>\n      <td>0.000672</td>\n      <td>0.026268</td>\n      <td>4.571441e-06</td>\n      <td>2.903764e-06</td>\n      <td>3.132365e-05</td>\n      <td>3.466806e-04</td>\n      <td>3.492374e-02</td>\n      <td>0.000149</td>\n      <td>2.000439e-05</td>\n      <td>0.000369</td>\n      <td>1.338044e-03</td>\n      <td>3.982928e-04</td>\n      <td>5.649381e-05</td>\n      <td>4.395702e-03</td>\n      <td>1.394045e-02</td>\n      <td>8.687613e-04</td>\n      <td>1.727450e-04</td>\n      <td>4.597991e-04</td>\n      <td>2.301811e-05</td>\n      <td>2.904742e-04</td>\n      <td>3.732721e-04</td>\n      <td>8.402640e-05</td>\n      <td>1.085599e-07</td>\n      <td>0.000250</td>\n      <td>...</td>\n      <td>1.453728e-03</td>\n      <td>8.734466e-02</td>\n      <td>8.290728e-03</td>\n      <td>1.459409e-04</td>\n      <td>3.829252e-04</td>\n      <td>1.235150e-04</td>\n      <td>0.028401</td>\n      <td>0.231138</td>\n      <td>1.160992e-02</td>\n      <td>4.729814e-01</td>\n      <td>9.531206e-04</td>\n      <td>7.486226e-04</td>\n      <td>1.829613e-03</td>\n      <td>2.491417e-03</td>\n      <td>7.356184e-07</td>\n      <td>9.112000e-05</td>\n      <td>2.348217e-05</td>\n      <td>1.185400e-06</td>\n      <td>9.130159e-04</td>\n      <td>8.107526e-07</td>\n      <td>1.915725e-03</td>\n      <td>6.510400e-08</td>\n      <td>3.573656e-04</td>\n      <td>7.201362e-03</td>\n      <td>3.564973e-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3128</td>\n      <td>0.000444</td>\n      <td>0.000009</td>\n      <td>9.982874e-05</td>\n      <td>2.026598e-04</td>\n      <td>5.966680e-06</td>\n      <td>4.726128e-05</td>\n      <td>4.240780e-06</td>\n      <td>0.000141</td>\n      <td>1.050581e-03</td>\n      <td>0.000019</td>\n      <td>2.445121e-04</td>\n      <td>7.195385e-05</td>\n      <td>3.480275e-06</td>\n      <td>2.057023e-06</td>\n      <td>2.487789e-05</td>\n      <td>2.828537e-04</td>\n      <td>3.279070e-07</td>\n      <td>3.549706e-06</td>\n      <td>2.182547e-06</td>\n      <td>1.598718e-06</td>\n      <td>3.212181e-06</td>\n      <td>6.472810e-05</td>\n      <td>3.767232e-05</td>\n      <td>0.000081</td>\n      <td>...</td>\n      <td>2.424678e-04</td>\n      <td>1.056190e-06</td>\n      <td>5.237694e-05</td>\n      <td>9.614967e-07</td>\n      <td>7.052824e-06</td>\n      <td>4.694936e-06</td>\n      <td>0.000014</td>\n      <td>0.000024</td>\n      <td>1.516358e-05</td>\n      <td>2.212631e-05</td>\n      <td>7.816576e-06</td>\n      <td>3.818717e-05</td>\n      <td>2.224833e-03</td>\n      <td>6.101608e-03</td>\n      <td>8.398696e-04</td>\n      <td>1.489779e-04</td>\n      <td>9.851968e-06</td>\n      <td>2.031352e-05</td>\n      <td>2.558382e-05</td>\n      <td>3.767787e-05</td>\n      <td>1.848217e-06</td>\n      <td>3.832962e-05</td>\n      <td>1.474924e-05</td>\n      <td>3.222499e-06</td>\n      <td>6.864996e-03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3129</td>\n      <td>0.001811</td>\n      <td>0.000027</td>\n      <td>1.599152e-06</td>\n      <td>5.231936e-04</td>\n      <td>4.356049e-04</td>\n      <td>3.635793e-05</td>\n      <td>9.546840e-07</td>\n      <td>0.000003</td>\n      <td>1.444059e-05</td>\n      <td>0.000040</td>\n      <td>2.423781e-05</td>\n      <td>6.675769e-06</td>\n      <td>8.358064e-07</td>\n      <td>4.521470e-07</td>\n      <td>2.454368e-05</td>\n      <td>4.665540e-04</td>\n      <td>9.037330e-06</td>\n      <td>1.200840e-05</td>\n      <td>1.359197e-04</td>\n      <td>2.191336e-06</td>\n      <td>4.354409e-06</td>\n      <td>7.573354e-06</td>\n      <td>1.892100e-04</td>\n      <td>0.000011</td>\n      <td>...</td>\n      <td>1.491847e-05</td>\n      <td>2.577658e-07</td>\n      <td>2.068980e-05</td>\n      <td>1.917756e-06</td>\n      <td>9.711699e-07</td>\n      <td>6.547080e-06</td>\n      <td>0.000040</td>\n      <td>0.000031</td>\n      <td>7.696641e-08</td>\n      <td>5.184464e-07</td>\n      <td>1.530681e-05</td>\n      <td>2.533567e-06</td>\n      <td>4.491681e-04</td>\n      <td>7.765405e-04</td>\n      <td>4.753325e-04</td>\n      <td>9.975126e-06</td>\n      <td>8.568231e-07</td>\n      <td>1.432784e-05</td>\n      <td>2.281642e-06</td>\n      <td>4.715525e-06</td>\n      <td>1.309887e-06</td>\n      <td>1.383369e-03</td>\n      <td>5.538989e-05</td>\n      <td>2.613220e-06</td>\n      <td>5.682869e-03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>777</th>\n      <td>3902</td>\n      <td>0.003376</td>\n      <td>0.000024</td>\n      <td>9.289932e-07</td>\n      <td>2.241921e-04</td>\n      <td>6.610556e-04</td>\n      <td>7.387674e-05</td>\n      <td>5.232951e-07</td>\n      <td>0.000005</td>\n      <td>4.411094e-05</td>\n      <td>0.000009</td>\n      <td>1.146871e-05</td>\n      <td>5.468364e-07</td>\n      <td>1.348126e-07</td>\n      <td>2.086083e-07</td>\n      <td>4.269572e-06</td>\n      <td>5.250274e-04</td>\n      <td>1.108902e-05</td>\n      <td>8.549371e-06</td>\n      <td>2.838518e-04</td>\n      <td>2.184845e-06</td>\n      <td>2.186964e-06</td>\n      <td>3.047839e-06</td>\n      <td>2.014188e-04</td>\n      <td>0.000004</td>\n      <td>...</td>\n      <td>5.442039e-06</td>\n      <td>1.301118e-07</td>\n      <td>1.054748e-05</td>\n      <td>1.026104e-07</td>\n      <td>3.990949e-06</td>\n      <td>7.954625e-06</td>\n      <td>0.000008</td>\n      <td>0.000003</td>\n      <td>1.609850e-07</td>\n      <td>4.242834e-07</td>\n      <td>1.483794e-05</td>\n      <td>2.448846e-06</td>\n      <td>2.470944e-04</td>\n      <td>4.117446e-04</td>\n      <td>7.730624e-04</td>\n      <td>6.550279e-07</td>\n      <td>7.858764e-08</td>\n      <td>3.598512e-06</td>\n      <td>5.697138e-07</td>\n      <td>1.385776e-06</td>\n      <td>1.042821e-06</td>\n      <td>2.662610e-03</td>\n      <td>1.546706e-05</td>\n      <td>3.246937e-06</td>\n      <td>2.529361e-03</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>3903</td>\n      <td>0.000046</td>\n      <td>0.000003</td>\n      <td>2.171766e-07</td>\n      <td>2.634886e-04</td>\n      <td>5.808211e-05</td>\n      <td>2.498243e-05</td>\n      <td>1.181050e-08</td>\n      <td>0.000001</td>\n      <td>1.973592e-07</td>\n      <td>0.000001</td>\n      <td>1.834327e-07</td>\n      <td>3.506831e-08</td>\n      <td>4.530533e-09</td>\n      <td>1.919050e-08</td>\n      <td>1.093814e-07</td>\n      <td>1.139006e-04</td>\n      <td>1.085911e-05</td>\n      <td>2.973405e-06</td>\n      <td>5.885158e-05</td>\n      <td>4.363570e-07</td>\n      <td>1.138996e-06</td>\n      <td>7.555505e-07</td>\n      <td>9.977297e-04</td>\n      <td>0.000002</td>\n      <td>...</td>\n      <td>2.731617e-07</td>\n      <td>1.333596e-08</td>\n      <td>4.436761e-07</td>\n      <td>2.557141e-09</td>\n      <td>4.947949e-06</td>\n      <td>2.176467e-05</td>\n      <td>0.000004</td>\n      <td>0.000001</td>\n      <td>4.065248e-09</td>\n      <td>1.587645e-08</td>\n      <td>1.179277e-06</td>\n      <td>1.595002e-07</td>\n      <td>1.565475e-05</td>\n      <td>4.792718e-05</td>\n      <td>3.617416e-05</td>\n      <td>2.020144e-07</td>\n      <td>2.688058e-09</td>\n      <td>5.081118e-06</td>\n      <td>3.864673e-07</td>\n      <td>1.108734e-06</td>\n      <td>6.860322e-07</td>\n      <td>1.589115e-03</td>\n      <td>2.275958e-06</td>\n      <td>4.922045e-07</td>\n      <td>3.214272e-05</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>3904</td>\n      <td>0.000432</td>\n      <td>0.000005</td>\n      <td>5.834871e-06</td>\n      <td>2.168282e-04</td>\n      <td>1.245494e-05</td>\n      <td>5.532837e-05</td>\n      <td>2.084059e-06</td>\n      <td>0.000017</td>\n      <td>1.737914e-05</td>\n      <td>0.000020</td>\n      <td>3.347022e-05</td>\n      <td>4.028117e-06</td>\n      <td>3.079397e-07</td>\n      <td>3.438513e-07</td>\n      <td>1.676546e-05</td>\n      <td>1.481532e-04</td>\n      <td>3.614811e-07</td>\n      <td>8.481842e-07</td>\n      <td>2.230498e-06</td>\n      <td>5.927222e-07</td>\n      <td>2.632754e-06</td>\n      <td>3.697830e-05</td>\n      <td>8.000265e-05</td>\n      <td>0.000016</td>\n      <td>...</td>\n      <td>1.018092e-04</td>\n      <td>2.778946e-07</td>\n      <td>7.045038e-06</td>\n      <td>3.608197e-07</td>\n      <td>1.565169e-06</td>\n      <td>2.798694e-06</td>\n      <td>0.000004</td>\n      <td>0.000011</td>\n      <td>4.437944e-07</td>\n      <td>1.779633e-06</td>\n      <td>1.530016e-06</td>\n      <td>1.453326e-05</td>\n      <td>6.313912e-04</td>\n      <td>1.967291e-03</td>\n      <td>1.213715e-04</td>\n      <td>1.171371e-05</td>\n      <td>5.068287e-07</td>\n      <td>1.091375e-05</td>\n      <td>1.502929e-05</td>\n      <td>1.100640e-05</td>\n      <td>6.298472e-07</td>\n      <td>6.372209e-05</td>\n      <td>1.529520e-05</td>\n      <td>7.411815e-07</td>\n      <td>1.249704e-03</td>\n    </tr>\n    <tr>\n      <th>780</th>\n      <td>3905</td>\n      <td>0.000006</td>\n      <td>0.000601</td>\n      <td>4.421241e-07</td>\n      <td>2.577478e-09</td>\n      <td>1.550255e-08</td>\n      <td>4.920408e-08</td>\n      <td>8.814055e-03</td>\n      <td>0.000012</td>\n      <td>2.349413e-08</td>\n      <td>0.000008</td>\n      <td>5.321275e-06</td>\n      <td>2.676131e-05</td>\n      <td>2.608368e-08</td>\n      <td>4.612240e-04</td>\n      <td>5.015236e-07</td>\n      <td>1.233775e-07</td>\n      <td>5.471856e-06</td>\n      <td>5.796545e-07</td>\n      <td>2.409827e-09</td>\n      <td>3.810382e-07</td>\n      <td>1.035291e-07</td>\n      <td>5.019211e-06</td>\n      <td>9.058112e-09</td>\n      <td>0.000006</td>\n      <td>...</td>\n      <td>3.239656e-05</td>\n      <td>9.890268e-01</td>\n      <td>1.599520e-06</td>\n      <td>1.074810e-07</td>\n      <td>6.554482e-06</td>\n      <td>1.289670e-07</td>\n      <td>0.000022</td>\n      <td>0.000015</td>\n      <td>5.835751e-05</td>\n      <td>6.031017e-04</td>\n      <td>7.186250e-07</td>\n      <td>1.242279e-04</td>\n      <td>5.051617e-07</td>\n      <td>7.716503e-07</td>\n      <td>2.039447e-09</td>\n      <td>1.477869e-06</td>\n      <td>2.508699e-08</td>\n      <td>1.340853e-07</td>\n      <td>2.458059e-05</td>\n      <td>3.287898e-08</td>\n      <td>2.375942e-05</td>\n      <td>3.813196e-11</td>\n      <td>1.209296e-07</td>\n      <td>3.813836e-06</td>\n      <td>1.245364e-08</td>\n    </tr>\n    <tr>\n      <th>781</th>\n      <td>3906</td>\n      <td>0.000077</td>\n      <td>0.000004</td>\n      <td>8.409019e-07</td>\n      <td>1.342619e-04</td>\n      <td>8.561942e-05</td>\n      <td>5.342241e-05</td>\n      <td>9.995349e-08</td>\n      <td>0.000005</td>\n      <td>2.060849e-07</td>\n      <td>0.000003</td>\n      <td>1.188621e-05</td>\n      <td>2.228837e-07</td>\n      <td>5.417503e-08</td>\n      <td>3.117734e-07</td>\n      <td>9.369535e-06</td>\n      <td>7.194764e-05</td>\n      <td>5.408833e-06</td>\n      <td>1.244227e-06</td>\n      <td>1.200303e-05</td>\n      <td>8.673358e-07</td>\n      <td>1.331399e-06</td>\n      <td>1.980636e-06</td>\n      <td>8.965555e-04</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>3.372931e-06</td>\n      <td>8.484487e-08</td>\n      <td>6.479303e-06</td>\n      <td>1.596174e-08</td>\n      <td>4.953384e-06</td>\n      <td>3.489677e-05</td>\n      <td>0.000048</td>\n      <td>0.000009</td>\n      <td>6.950701e-08</td>\n      <td>2.413539e-07</td>\n      <td>1.531095e-06</td>\n      <td>6.023533e-07</td>\n      <td>4.895016e-05</td>\n      <td>1.692420e-04</td>\n      <td>1.069355e-04</td>\n      <td>2.124048e-07</td>\n      <td>2.577672e-08</td>\n      <td>1.721582e-06</td>\n      <td>1.011961e-06</td>\n      <td>4.961008e-07</td>\n      <td>3.626475e-07</td>\n      <td>3.123985e-03</td>\n      <td>2.396042e-04</td>\n      <td>1.297963e-06</td>\n      <td>2.969784e-04</td>\n    </tr>\n  </tbody>\n</table>\n<p>782 rows × 62 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "submission=pd.read_csv('./open/sample_submission.csv')\n",
    "submission.iloc[:,1:]=pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sub_kfold_stratified_10_adam_fft_0.5.csv',index=False)"
   ]
  }
 ]
}