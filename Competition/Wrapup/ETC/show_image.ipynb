{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision import transforms \n",
    "import time, os, sys, copy, random \n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob \n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_df=pd.read_csv('./input/data/train/train.csv')\n",
    "import time\n",
    "import glob,shutil\n",
    "new_img_dir='./input/data/train/new_img'\n",
    "if not os.path.exists(new_img_dir):\n",
    "    os.mkdir(new_img_dir)\n",
    "for idx,i in enumerate(train_df.values):\n",
    "    gender= i[1]\n",
    "    age=i[3]\n",
    "    path=i[4]\n",
    "    img_path=os.path.join('./input/data/train/new_img',path)\n",
    "    \n",
    "    fig,ax=plt.subplots(1,7,dpi=300)\n",
    "    plt.title(f'num={path} gender={gender} age={age}',loc='left')\n",
    "    for idx,imgs in enumerate(os.listdir(img_path)):\n",
    "        \n",
    "        image=cv2.imread(os.path.join(img_path,imgs))\n",
    "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)  \n",
    "        ax[idx].axis('off')\n",
    "        ax[idx].imshow(image)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512, 384), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths,transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=7\n",
    ")\n",
    "for imgs in loader:\n",
    "    images= imgs\n",
    "    images=images.numpy()\n",
    "    fig,ax=plt.subplots(dpi=300)# batch, channel, height,width\n",
    "    ax.imshow(np.hstack(images.transpose((0,2,3,1))))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('./input/data/eval/info.csv')\n",
    "fig,ax =plt.subplots(10,10)\n",
    "for i in test_df.values:\n",
    "    img_path=os.path.join('./input/data/eval/new_images',i[0])\n",
    "    image=cv2.imread(img_path)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    ax[i//10,i%10].axis('off')\n",
    "    ax[i//10,i%10].imshow(image)\n",
    "    if i==9999:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, RandomRotation, ColorJitter\n",
    "from PIL import Image\n",
    "\n",
    "test_dir='./input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'new_images')\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample={'image':image,'name':self.img_paths[index]}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    Resize((512,256),Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "#     Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2)),\n",
    "])\n",
    "dataset = TestDataset(image_paths,transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=7\n",
    ")\n",
    "for sample in loader:\n",
    "    images= sample['image']\n",
    "    print(sample['name'])\n",
    "    images=images.numpy()\n",
    "    fig,ax=plt.subplots(dpi=300)# batch, channel, height,width\n",
    "    ax.imshow(np.hstack(images.transpose((0,2,3,1))))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "import os \n",
    "#os.remove('./input/data/train/new_img/000523_female_Asian_51/mask4.jpg')\n",
    "shutil.copyfile('./input/data/train/images/000523_female_Asian_51/mask4.jpg','./input/data/train/new_img/000523_female_Asian_51/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image= cv2.imread('/opt/ml/input/data/train/images/000523_female_Asian_51/mask4.jpg')\n",
    "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.imsave('/opt/ml/input/data/train/new_img/000523_female_Asian_51/mask4.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -a '/opt/ml/input/data/train/images/000523_female_Asian_51'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -a '/opt/ml/input/data/train/new_img/001498-1_male_Asian_23/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-triple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import cv2,os\n",
    "\n",
    "error_df=pd.read_csv('/opt/ml/input/data/eval/info.csv')\n",
    "for i in error_df.iloc[:,0].values:\n",
    "    image=cv2.imread(os.path.join('/opt/ml/input/data/eval/new_images',i))\n",
    "    assert image is not None, f'{i} this is erroe image'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
