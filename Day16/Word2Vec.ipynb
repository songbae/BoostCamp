{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### Spacy 를 이용한 전처리\n",
    "---\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import spacy \n",
    "nlp=spacy.load('en_core_web_sm')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenezation\n",
    "\n",
    "text= nlp('Naver Connect and Upstage Boostcamp')\n",
    "print([token.text for token in text])\n",
    "\n",
    "doc= nlp(\n",
    "    'This annsigmnet is about Natural Language Processing'\n",
    "    'In this assignmnet, we will do prerpocessing'\n",
    ")\n",
    "print([token.text for token in doc])\n",
    "\n",
    "text=nlp(\"The film's development began when Marvel Studios received a loan from Merrill Lynch in April 2005. After the success of the film Iron Man in May 2008, \\\n",
    "Marvel announced that The Avengers would be released in July 2011 and would bring together Tony Stark, Steve Rogers, Bruce Banner, and Thor from Marvel's previous films. \\\n",
    "With the signing of Johansson as Natasha Romanoff in March 2009, the film was pushed back for a 2012 release. Whedon was brought on board in April 2010 and rewrote the original screenplay by Zak Penn. Production began in April 2011 in Albuquerque, \\\n",
    "New Mexico, before moving to Cleveland, Ohio in August and New York City in September. The film has more than 2,200 visual effects shots.\")"
   ]
  },
  {
   "source": [
    "### 불용어(StopWord)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords= spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(type(spacy_stopwords))\n",
    "for stop_word in list(spacy_stopwords)[:30]:\n",
    "    print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization \n",
    "\n",
    "for token in text[:20]:\n",
    "    print(token,'-',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그 외 token class의 attributes \n",
    "# http://spacy.io/api/token#attributes\n",
    "\n",
    "print(\"token \\t is punct \\t is_space \\t shape_ \\t is_stop\")\n",
    "print(\"=\"*70)\n",
    "for token in text[21:31]:\n",
    "    print(token, '\\t',token.is_punct,\"\\t\\t\", token.is_space,\"\\t\\t\",token.shape_,\"\\t\\t\",token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_token_allowed(token):\n",
    "    if (token in spacy_stopwords) or (token.is_punct==True) or (token.is_stop==True):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess_token(token):\n",
    "    # lemmatization을 실행부분\n",
    "    return token.lemma_.strip().lower()\n",
    "\n",
    "answer=['film', 'development','begin', 'marvel','studios', 'receive','loan', 'merrill','lynch', 'april','2005', 'success','film', 'iron','man', '2008','marvel','announce', 'avengers','release', 'july','2011', 'bring','tony', 'stark','steve', 'rogers','bruce', 'banner','thor', 'marvel','previous', 'film','signing', 'johansson','natasha','romanoff','march','2009','film','push','2012','release','whedon','bring','board','april','2010','rewrote','original','screenplay','zak','penn','production','begin','april','2011','albuquerque','new','mexico','move','cleveland','ohio','august','new','york','city','september','film','2,200','visual','effect','shot']\n",
    "\n",
    "for token in text:\n",
    "    filtered_tokens=[preprocess_token(token) for token in text if is_token_allowed(token)]\n",
    "print(filtered_tokens)\n",
    "assert filtered_tokens==answer"
   ]
  },
  {
   "source": [
    "### 한국어 전처리 \n",
    "---\n",
    "\n",
    "- Mecab를 이용한 형태소 분석 기반 토크나이징 \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/SOMJANG/Mecab-ko\n",
    "!bash install_mecab-ko_on_colab190912.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eunjeon import MeCab\n",
    "import operator\n",
    "tokenizer=Mecab('./Mecab-ko-for-Goolge-Colab')"
   ]
  }
 ]
}