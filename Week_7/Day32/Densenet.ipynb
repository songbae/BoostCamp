{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torchvision.utils import save_image\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import glob\r\n",
    "import PIL\r\n",
    "from PIL import Image\r\n",
    "from torch.utils import data as D\r\n",
    "from  torch.utils.data.sampler import SubsetRandomSampler\r\n",
    "import random\r\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 166379520/170498071 [01:12<00:01, 2306482.55it/s] \n",
      "170500096it [00:34, 4873448.31it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "\r\n",
    "batch_size = 64\r\n",
    "validation_rate = 0.1\r\n",
    "random_seed = 10\r\n",
    "lr = 1e-1\r\n",
    "epoches = 300\r\n",
    "\r\n",
    "transform_train = transforms.Compose([\r\n",
    "  transforms.RandomCrop(32, padding=4),\r\n",
    "  transforms.RandomHorizontalFlip(),\r\n",
    "  transforms.ToTensor(),\r\n",
    "  transforms.Normalize((0.4914,0.4822,0.4465),(0.2470,0.2435,0.2616))\r\n",
    "])\r\n",
    "transform_valid = transforms.Compose([\r\n",
    "  transforms.ToTensor(),\r\n",
    "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\r\n",
    "])\r\n",
    "transform_test = transforms.Compose([\r\n",
    "  transforms.ToTensor(),\r\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\r\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\r\n",
    "validset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_valid)\r\n",
    "testset=torchvision.datasets.CIFAR100(root='./data',train=False,download=True,transform=transfrom_test)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "num_trains = len(trainset)\r\n",
    "indice = list(range(num_trains))\r\n",
    "spilt = int(np.floor(validation_rate * num_trains))\r\n",
    "\r\n",
    "np.random.seed(random_seed)\r\n",
    "np.random.shuffle(indice)\r\n",
    "\r\n",
    "train_idx, valid_idx = indice[spilt:], indice[:spilt]\r\n",
    "train_sampler = SubsetRandomSampler(train_idx)\r\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\r\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0)\r\n",
    "valid_loader = DataLoader(validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0)\r\n",
    "test_loader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=0)\r\n",
    "\r\n",
    "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_model(nn.Module):\r\n",
    "  def __init__(self, nin, nout, kernel_size, stride, padding, bias=False):\r\n",
    "    super(conv, self).__init__()\r\n",
    "    self.bn = nn.BatchNorm2d(nin)\r\n",
    "    self.relu = nn.ReLU()\r\n",
    "    self.conv = nn.Conv2d(nin, nout, kernel_size=kernel_size, stride=stride, padding=padding)\r\n",
    "    \r\n",
    "  def forward(self, x):\r\n",
    "    out = self.batch_norm(x)\r\n",
    "    out = self.relu(out)\r\n",
    "    out = self.conv(out)\r\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "class bottlenect(nn.Module):\r\n",
    "  def __init__(self, nin, growth_rate, drop_rate=0.2):\r\n",
    "    super(bottlenect, self).__init__()\r\n",
    "    self.add_module('conv1x1', conv_model(nin=nin, nout=growth_rate * 4, kernel_size=1, stride=1, padding=0, bias=False))\r\n",
    "    self.add_module('con3x3', conv_model(nin=growth_rate * 4, nout=growth_rate, kernel_size=3, stride=1, padding=1, bias=False))\r\n",
    "    self.drop_rate = drop_rate\r\n",
    "    \r\n",
    "  def forward(self, x):\r\n",
    "    bottlenect_output = super(bottlenect, self).forward(x)\r\n",
    "    if self.drop_rate > 0:\r\n",
    "      bottlenect_output = F.dropout(bottlenect_output, p=self.drop_rate, training=self.training)  # 트레이닝은 없는 값인데 문제가 되지않나용ㅇ?\r\n",
    "      \r\n",
    "    bottlenect_output = torch.cat((x, bottlenect_output), 1) # 1이 디멘션을 얘기한다는데 concat 을 할때 하지만 기본값이 (3,64,64)라고 하면 3이 채널값인데 0을 넣어주는게 맞지않나 \r\n",
    "    \r\n",
    "    return bottlenect_output\r\n",
    "\r\n",
    "\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "class transition_layer(nn.Sequential):\r\n",
    "  def __init__(self, nin, theta=.5):\r\n",
    "    super(transition_layer, self).__init__()\r\n",
    "    self.add_module('conv_1x1', conv_model(nin=nin, nout=int(nin * theta), kernel_size=1, stride=1, padding=0, bias=False))\r\n",
    "    self.add_module('avg_pool_2x2', nn.AvgPool2d(kernel_size=2, stride=2, padding=0))\r\n",
    "    \r\n",
    "class denseblock(nn.Sequential):\r\n",
    "  def __init__(self, nin, nout,nin_bottlenect, growth_rate, drop_rate=0.2):\r\n",
    "    super(denseblock, self).__init__()\r\n",
    "    \r\n",
    "    for i in range(bottlenect):\r\n",
    "      nin_bottlenect = nin + growth_rate * i\r\n",
    "      self.add_module('bottlenect_%d %i', bottlenect(nin=nin_bottlenect, growth_rate=growth_rate, drop_rate=drop_rate))\r\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "class Densenet(nn.Module):\r\n",
    "  def __init__(self, growth_rate=12, num_layers=100, theta=.5, drop_rate=0.2, num_classes=10):\r\n",
    "    super(Densenet, self).__init__()\r\n",
    "    assert (num_layers - 4) % 6 == 0\r\n",
    "    \r\n",
    "    #\r\n",
    "    num_bottleneck_layers = (num_layers - 4) // 6\r\n",
    "    self.dense_init = nn.Con2d(3, growth_rate * 2, kernel_size=3, stride=1, padding=1, bias=True)\r\n",
    "    self.dense_block_1 = denseblock(nin=growth_rate * 2, num_bottleneck_layers=num_bottleneck_layers, growth_rate=growth_rate, drop_rate=drop_rate)\r\n",
    "    nin_transition_layer_1 = growth_rate * 2 + growth_rate * num_bottleneck_layers\r\n",
    "    self.transition_layer_1 = transition_layer(nin=nin_transition_layer_1, theta=theta)\r\n",
    "    self.dense_block_2 = denseblock(nin=int(nin_transition_layer_1 * theta), num_bottleneck_layers=num_bottleneck_layers)\r\n",
    "    \r\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "a955008dc820c70e8c41cf6f115bde945f96d07d69c96eec2ee76e53bea50083"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}