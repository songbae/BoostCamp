{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7. Pruning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB3VdM2CRMIC"
      },
      "source": [
        "## 주안점\r\n",
        "#### Pruning 전/후 model size 비교\r\n",
        "\r\n",
        "- [참고] https://pytorch.org/tutorials/intermediate/pruning_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ti_Q1t1UBA"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zbgc4NBMq_o"
      },
      "source": [
        "# 모델 생성\n",
        "먼저 프루닝을 수행하기 위한 간단한 모델을 생성하고 훈련시켜 봅시다.\n",
        "\n",
        "모델은 LeNet5, 데이터는 Mnist를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMSlmDCGUIYX"
      },
      "source": [
        "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
        "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                                    ])),\n",
        "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
        "\n",
        "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
        "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                                    ])),\n",
        "              batch_size=64, shuffle=False, num_workers=1, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "39pOm4tjUrV6",
        "outputId": "2a56f120-5e3a-404a-cbc1-a3156ad45e01"
      },
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = 20\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "print(labels[1:21])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n",
            "tensor([8, 3, 8, 9, 4, 7, 5, 2, 5, 3, 4, 2, 9, 2, 6, 0, 6, 5, 8, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-6SmhckMTvO"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LeNet().to(device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTJNZzy8MXfo"
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, criterion, epoch):\n",
        "    \"\"\" Train the model with given dataset\n",
        "    \n",
        "    Args:\n",
        "        args: args like log interval\n",
        "        model: ResNet model to train\n",
        "        device: CPU/GPU\n",
        "        train_loader: dataset iterator\n",
        "        optimizer: optimizer to update weights\n",
        "        epoch: number of epochs to train for\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % args[\"log_interval\"] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87FmftGKSIto",
        "outputId": "053dc4d2-3fd5-4772-85c9-8c3d22afe5e5"
      },
      "source": [
        "batch_size = 64\r\n",
        "epochs = 10\r\n",
        "lr = 0.001\r\n",
        "momentum = 0.9\r\n",
        "seed = 1\r\n",
        "log_interval = 500\r\n",
        "save_model = True\r\n",
        "no_cuda = False\r\n",
        "\r\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\r\n",
        "torch.manual_seed(seed)\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "model = LeNet().to(device)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "args = {}\r\n",
        "args[\"log_interval\"] = log_interval\r\n",
        "for epoch in range(1, epochs + 1):\r\n",
        "    train(args, model, device, train_loader, optimizer, criterion, epoch)\r\n",
        "\r\n",
        "if (save_model):\r\n",
        "    torch.save(model.state_dict(),\"mnist_cnn.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308216\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.293523\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.183794\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.084196\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.016178\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.045889\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.052779\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.006105\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.041600\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.053083\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.017430\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.005766\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.036655\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.014016\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.010713\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.056435\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.002388\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.007688\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.064038\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.055111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9ftFwREVifL",
        "outputId": "61314d59-32b2-45e1-bf9d-138320b37d4b"
      },
      "source": [
        "def print_size_of_model(model):\n",
        "    \"\"\" Print the size of the model.\n",
        "    \n",
        "    Args:\n",
        "        model: model whose size needs to be determined\n",
        "\n",
        "    \"\"\"\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "  \n",
        "print_size_of_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the model(MB): 0.243543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvyGuZtVjN6"
      },
      "source": [
        "def test(model, device, test_loader, quantize=False, fbgemm=False):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(model)\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            st = time.time()\n",
        "            output = model(data)\n",
        "            et = time.time()\n",
        "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    \n",
        "    print(\"========================================= PERFORMANCE =============================================\")\n",
        "    print_size_of_model(model)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
        "    print(\"====================================================================================================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "319h_l8HW4zt",
        "outputId": "0d22ea0f-715e-43f4-b1b7-62b42ca2eee8"
      },
      "source": [
        "device = 'cpu'\n",
        "test(model=model, device=device, test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "========================================= PERFORMANCE =============================================\n",
            "Size of the model(MB): 0.243543\n",
            "\n",
            "Test set: Average loss: 0.0400, Accuracy: 9894/10000 (99%)\n",
            "\n",
            "Elapsed time = 3.0844 milliseconds\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wFFtDTJMp7s"
      },
      "source": [
        "# 레이어 weight 확인\n",
        "먼저 생성된 모델의 첫 번째 레이어를 구성하는 파라미터 들을 확인해봅시다.\n",
        "weight와 bias로 구성이 되어 있는 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmbHBZEuM2oH",
        "outputId": "12538baa-f386-487f-f594-747b78109db8"
      },
      "source": [
        "module = model.conv1\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[ 0.1590, -0.1615, -0.1669],\n",
            "          [ 0.1205, -0.1740,  0.2915],\n",
            "          [-0.0406,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0529,  0.1204],\n",
            "          [-0.0321,  0.2103,  0.0951]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3417,  0.0608, -0.5403],\n",
            "          [-0.1888,  0.0631, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.1534,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.2413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.4016,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.4005, -0.2626]]]], requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([ 0.2126,  0.0797,  0.0186, -0.1048,  0.2026,  0.3839],\n",
            "       requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itF_G9Uf16FW",
        "outputId": "971e163d-19d6-4982-bd79-b4ea122d6df7"
      },
      "source": [
        "output_orig = model(images[:1])\r\n",
        "print(f\"original output: {output_orig}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original output: tensor([[  1.2011, -13.0009,  -9.4744, -13.6666,  -4.2937,   1.5315,  19.2637,\n",
            "         -21.1911,  -8.4866, -10.5521]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38gFa0uzhnfm"
      },
      "source": [
        "# Unstructured Pruning\n",
        "기본적인 프루닝 방법은 스칼라 단위의 값(=하나의 숫자)에 대해 프루닝을 하는 것입니다.\n",
        "\n",
        "Pytorch에서 제공하는 prune method를 이용하여 이를 수행해보겠습니다.\n",
        "프루닝할 값을 고르는 방법 또한 여러가지입니다만, 우선 random으로 선택하는 방식을 적용해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "652QSScGhxov"
      },
      "source": [
        "import torch.nn.utils.prune as prune"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbdyH0jjzgsj",
        "outputId": "e2c0e9ed-7808-464a-ff5c-02cf6572bcb4"
      },
      "source": [
        "prune.random_unstructured(module, name=\"weight\", amount=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVsSTYoXzi-J",
        "outputId": "a1fc9d65-78ef-4bd5-93d7-62f662a03d7b"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bias', Parameter containing:\n",
            "tensor([ 0.2126,  0.0797,  0.0186, -0.1048,  0.2026,  0.3839],\n",
            "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.1590, -0.1615, -0.1669],\n",
            "          [ 0.1205, -0.1740,  0.2915],\n",
            "          [-0.0406,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0529,  0.1204],\n",
            "          [-0.0321,  0.2103,  0.0951]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3417,  0.0608, -0.5403],\n",
            "          [-0.1888,  0.0631, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.1534,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.2413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.4016,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.4005, -0.2626]]]], requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz7vmYxmz_JC"
      },
      "source": [
        "기존 레이어는 'weight', 'bias'로 구성이 되어있었던 파라미터가 'weight_orig', 'bias'라는 이름으로 바뀐 것을 볼 수 있습니다. 'weight'가 'weight_orig'라는 이름으로 바뀌었네요\n",
        "\n",
        "하지만 값은 전혀 변한 것이 없습니다. 그러면 무엇이 수행이 된 것일까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMADExKO0pp-",
        "outputId": "4630387b-3a54-4a70-d015-73220e64ed2f"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_mask', tensor([[[[0., 1., 0.],\n",
            "          [0., 0., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 0., 0.]]]]))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ2DCH-P1Jot"
      },
      "source": [
        "prune 함수를 수행하고 나면, 레이어의 named_buffers()에 'weight_mask'라는 새로운 파라미터가 하나 생성된 것을 볼 수 있습니다.\n",
        "\n",
        "\n",
        "프루닝이라면 일반적으로 특정 값을 0으로 만들어 영향력을 없애는 것으로 생각할 수 있습니다. 하지만 pytorch에서는 직접 값을 바로 0으로 바꾸는 대신, mask 텐서를 추가로 생성하여 프루닝을 수행하게 됩니다. 삭제할 값을 0, 보존할 값을 1로 설정한 mask 텐서를 생성한 후, 실제 계산을 수행할때 mask와 weight를 원소별로 곱한 텐서를 활용하게 되지요.\n",
        "\n",
        "pruning mask가 적용된 weight의 결과는 레이어의 weight 속성에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eua36t5M1WZP",
        "outputId": "d26d7fbc-249e-4ee0-a91b-e0f50f681173"
      },
      "source": [
        "print(module.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.0000, -0.1615, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.2915],\n",
            "          [-0.0000,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0000,  0.1204],\n",
            "          [-0.0321,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0608, -0.0000],\n",
            "          [-0.1888,  0.0000, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.0000,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.0000,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.0000, -0.0000]]]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s3tjkgfFtN1"
      },
      "source": [
        "그러면 기존 모델의 출력값과 첫번째 레이어를 가지치기한 모델의 결과를 비교해봅시다.\r\n",
        "값에 차이가 생긴 것을 볼 수가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkPZQElOEr7v",
        "outputId": "5b62e137-e028-4c1f-804c-33b30c70096f"
      },
      "source": [
        "output_pruned_conv1 = model(images[:1])\r\n",
        "print(f\"original output: {output_orig}\")\r\n",
        "print(f\"pruned weight output: {output_pruned_conv1}\")\r\n",
        "print(f\"difference: {output_orig - output_pruned_conv1}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original output: tensor([[  1.2011, -13.0009,  -9.4744, -13.6666,  -4.2937,   1.5315,  19.2637,\n",
            "         -21.1911,  -8.4866, -10.5521]], grad_fn=<AddmmBackward>)\n",
            "pruned weight output: tensor([[ -0.7283, -11.6755,  -7.3619,  -9.8739,  -4.1885,   3.5274,  15.3584,\n",
            "         -17.7473,  -7.3540,  -9.2162]], grad_fn=<AddmmBackward>)\n",
            "difference: tensor([[ 1.9294, -1.3254, -2.1125, -3.7926, -0.1051, -1.9959,  3.9052, -3.4438,\n",
            "         -1.1326, -1.3359]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgdIeWxR2o8S"
      },
      "source": [
        "전체 성능 테스트에서도 어느정도 성능이 떨어진 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mKTbf8B2hRV",
        "outputId": "af6c0892-c162-4e99-89df-00564f6c9102"
      },
      "source": [
        "device = 'cpu'\r\n",
        "test(model=model, device=device, test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "========================================= PERFORMANCE =============================================\n",
            "Size of the model(MB): 0.243995\n",
            "\n",
            "Test set: Average loss: 0.1297, Accuracy: 9588/10000 (96%)\n",
            "\n",
            "Elapsed time = 3.1300 milliseconds\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adkR97o3DvzH"
      },
      "source": [
        "이렇게 weight에 대해 프루닝을 적용해 보았습니다!\r\n",
        "\r\n",
        "이번에는 또 다른 parameter인 bias에 pruning을 적용해보겠습니다. random으로 값을 선택하여 가지치기한 weight와는 다르게, bias는 값이 작은 순서대로 프루닝을 수행해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOCYgVzhD_VR",
        "outputId": "8f1535b2-3bcb-49d6-ac04-70075f749362"
      },
      "source": [
        "prune.l1_unstructured(module, name=\"bias\", amount=3)  # amount를 float으로 입력하면 해당 비율만큼, int로 입력할 경우 해당 갯수만큼 값을 선택하여 가지치기합니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6LcNI3fEf9o",
        "outputId": "1b2369b2-85cc-42a7-8089-986e06461842"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.1590, -0.1615, -0.1669],\n",
            "          [ 0.1205, -0.1740,  0.2915],\n",
            "          [-0.0406,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0529,  0.1204],\n",
            "          [-0.0321,  0.2103,  0.0951]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3417,  0.0608, -0.5403],\n",
            "          [-0.1888,  0.0631, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.1534,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.2413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.4016,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.4005, -0.2626]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.2126,  0.0797,  0.0186, -0.1048,  0.2026,  0.3839],\n",
            "       requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-5Hsr6GM9O",
        "outputId": "3b399324-805d-4aad-f415-f330360cfb3c"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_mask', tensor([[[[0., 1., 0.],\n",
            "          [0., 0., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 1., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 0., 0.]]]])), ('bias_mask', tensor([1., 0., 0., 0., 1., 1.]))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-gvidouGOU4",
        "outputId": "05224d4f-d13d-4e94-c599-74701fc1d540"
      },
      "source": [
        "print(module.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.2126, 0.0000, 0.0000, -0.0000, 0.2026, 0.3839],\n",
            "       grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iUr-p3iSmoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca6b579-a6a7-4677-fbcd-985d589bf9cb"
      },
      "source": [
        "device = 'cpu'\r\n",
        "test(model=model, device=device, test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "========================================= PERFORMANCE =============================================\n",
            "Size of the model(MB): 0.244319\n",
            "\n",
            "Test set: Average loss: 0.1627, Accuracy: 9482/10000 (95%)\n",
            "\n",
            "Elapsed time = 2.9521 milliseconds\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCImByoP3L2A"
      },
      "source": [
        "# Model 크기 비교\r\n",
        "프루닝 된 모델의 크기를 출력하면, 프루닝되기 전의 모델보다 모델의 사이즈가 커진 것을 확인할 수 있습니다.\r\n",
        "\r\n",
        "상식적으로 가지치기가 되었다면 모델의 크기가 줄어들어야 할 텐데, 오히려 모델의 용량이 늘어난 것은 왜일까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK1SgI8GSmrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ab407f-77bf-4ecc-c0ac-0bf15fac0600"
      },
      "source": [
        "print_size_of_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the model(MB): 0.244319\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10BfjmQE4UC3"
      },
      "source": [
        "# 프루닝 영구 적용하기\r\n",
        "Pytorch에서 제공하는 prune method는 mask를 생성하는 방식으로 프루닝을 수행하는 것을 볼 수 있었습니다.\r\n",
        "\r\n",
        "이 때 원본 모델의 parameter는 \"weight_orig\", \"bias_orig\"과 같은 형태로 보존하는 것 또한 볼 수 있었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btaAHlYH9StX",
        "outputId": "a6d425cd-4555-41f9-ade2-916da25a80d6"
      },
      "source": [
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.1590, -0.1615, -0.1669],\n",
            "          [ 0.1205, -0.1740,  0.2915],\n",
            "          [-0.0406,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0529,  0.1204],\n",
            "          [-0.0321,  0.2103,  0.0951]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3417,  0.0608, -0.5403],\n",
            "          [-0.1888,  0.0631, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.1534,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.2413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.4016,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.4005, -0.2626]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.2126,  0.0797,  0.0186, -0.1048,  0.2026,  0.3839],\n",
            "       requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPkpsq2ELNUe"
      },
      "source": [
        "이러한 프루닝을 수행한 후 더 이상 원본 파라미터가 필요하지 않을 때, pruning을 영구히 적용하는 방법을 알아봅시다.\r\n",
        "\r\n",
        "prune.remove 함수를 사용하면, 기존의 원본 파라미터를 삭제하고 이를 prune이 적용된 weight를 교체하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kas8wU-r4Nwo",
        "outputId": "c52eb34e-4a92-4ebd-d42d-b6aa52787455"
      },
      "source": [
        "prune.remove(module, 'weight')\r\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bias_orig', Parameter containing:\n",
            "tensor([ 0.2126,  0.0797,  0.0186, -0.1048,  0.2026,  0.3839],\n",
            "       requires_grad=True)), ('weight', Parameter containing:\n",
            "tensor([[[[ 0.0000, -0.1615, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.2915],\n",
            "          [-0.0000,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0000,  0.1204],\n",
            "          [-0.0321,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0608, -0.0000],\n",
            "          [-0.1888,  0.0000, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.0000,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.0000,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.0000, -0.0000]]]], requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuieF2khL2DR"
      },
      "source": [
        "weight에 해당하는 mask 또한 없어진 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9G_h027_rpO",
        "outputId": "95ad501c-537e-4c7c-b43f-58c95e6c235a"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bias_mask', tensor([1., 0., 0., 0., 1., 1.]))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ow-G8pAMYei"
      },
      "source": [
        "마찬가지로 bias에 해당하는 prune도 영구 적용시켜보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y1uTaSF_mCC",
        "outputId": "8157e001-e575-460a-a7cd-b572edbfd008"
      },
      "source": [
        "prune.remove(module, 'bias')\r\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[ 0.0000, -0.1615, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.2915],\n",
            "          [-0.0000,  0.2925,  0.2390]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0723,  0.2015,  0.0201],\n",
            "          [ 0.1522,  0.0000,  0.1204],\n",
            "          [-0.0321,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000,  0.0608, -0.0000],\n",
            "          [-0.1888,  0.0000, -0.2171],\n",
            "          [-0.0986,  0.2166,  0.4315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3658, -0.0255,  0.2979],\n",
            "          [ 0.0000,  0.4578,  0.3480],\n",
            "          [-0.6110, -0.6698, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2878,  0.0912,  0.2625],\n",
            "          [ 0.0368,  0.4825, -0.1974],\n",
            "          [ 0.0000,  0.0993, -0.3863]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4993,  0.0597,  0.2199],\n",
            "          [-0.3226, -0.1980, -0.6864],\n",
            "          [-0.6618, -0.0000, -0.0000]]]], requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([0.2126, 0.0000, 0.0000, -0.0000, 0.2026, 0.3839], requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghABEy1qHhNJ",
        "outputId": "342e0fc8-9a74-42a4-a361-602e4e4c08ad"
      },
      "source": [
        "print(list(module.named_buffers()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKEH-6IhMkRu"
      },
      "source": [
        "mask를 제거하고 pruned weight를 영구히 적용시키니, 모델의 사이즈 또한 원래의 모델 사이즈와 동일해진 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D4_phTOHx7B",
        "outputId": "52e81df8-0e0c-497c-a82e-b31e24dc0d81"
      },
      "source": [
        "print_size_of_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the model(MB): 0.243543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnAnQ6c9MzyV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}