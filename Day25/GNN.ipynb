{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###정점 표현학습 \n",
    "---\n",
    "```\n",
    "정점 표현 학습이란 그래프의정점들을 벡터의 형태로 표현하는 것 이다.\n",
    "\n",
    "정점 표현 학습은 간단히 정점 임베딩이라고도 부른다. 정점 표현 학습의 입력은 그래프이다. 주어진 그래프의 각 정점 u에 대한 임베딩, 즉 벡터표현 .Zu가 정점 임베딩의 출력이다. \n",
    "\n",
    "\n",
    "그래프에서의 두 정점의 유사도는 어떻게 정의하나?\n",
    "인접성/거리/경로/중첩/임의보행 기반 접근법으로 나눈다.\n",
    "\n",
    "지금까지 소개한 정점 임베딩 방법들을 `변환식(Transductive)`방법이다.\n",
    "변환식 방법은 학습의 결과로 정점의 임베딩 자체를 얻는다는 특성이 있다. 정점을 임베딩으로 변화시키는 함수 즉 인코더를 얻는 귀납식 방법과 대조된다.\n",
    "\n",
    "\n",
    "변환식의 한계:\n",
    "\n",
    "1) 학습이 진행된 이후에 추가된 정점에 대해서는 임베딩을 얻을 수없다.\n",
    "2) 모든 정점에 대한 임베딩을 미리 계산하여 저장해두어야 한다.\n",
    "3) 정점이 속성(Atrribute) 정보를 가진 경우에 이를 활용할 수 없다.\n",
    "\n",
    "\n",
    "출력으로 인코더를 얻는 귀납식 임베딩 방법 장점:\n",
    "\n",
    "1) 학습이 진행된 이후에 추가된 정점에 대해서도 임베딩을 얻을 수 있다.\n",
    "2) 모든 정점에 대한 임베딩을 미리 계산하여  저장해둘 필요가 없다.\n",
    "3) 정점이 속성 정보를 가진 경우에 이를 활용할 수 있다.\n",
    "\n",
    "`GNN은 대표적인 귀납식 임베딩 방법`이다.\n",
    "\n",
    "``\n",
    "\n",
    "### 그래프 신경망 변형 \n",
    "\n",
    "---\n",
    "\n",
    "그래프 합성곱 신경망 \n",
    "\n",
    "GCN의 집계함수 : 정규화 방법 변화 \n",
    "\n",
    "GraphSAGE  의 집계함수 \n",
    "\n",
    "이웃들의 임베딩을 AGG함수를 이용해 합친후 자신의 임베딩과 연결하는 정점이 독특하다. \n",
    "\n",
    "MEAN. POOL, LSTM \n",
    "AGG함수로는 평균 폴링 LSTM 등이 사용될수 있다. \n",
    "\n",
    "\n",
    "### 합성공 신경망과 유사성 \n",
    "---\n",
    "\n",
    "합성공 신경망과 그래프 신경망은 모두 이웃의 정보를 집계하는 과정을 반복한다.\n",
    "\n",
    "그래프의 인접행렬에 합성곱 신경망을 적용하면 효과적인가?\n",
    "\n",
    "```\n",
    "그래프에는 합성곱 신경망이 아닌 그래프 신경망을 적용하여야 한다. 많은 분들이 흔히 범하는 실수이다.\n",
    "\n",
    "합성곱 신경망이 주로 쓰이는 이미지에서는 인접 픽셀이 유용한 정보를 담고 있을 가능성이 높다.\n",
    "하지만 그래프의 인접 행렬에서는 인접 원소는 제한된 정보를 가진다. 특히나 인접 행렬의 행과 열의 순서는 임의로 결정되는 경우가 많다.\n",
    "\n",
    "```\n",
    "\n",
    "###실습 DGL 라이브러리와 GraphSAGE를 이용한 정점 분류 \n",
    "---\n",
    "import numpy as np \n",
    "import time \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import dgl \n",
    "from dgl.data import CoraGraphDataset \n",
    "from dgl.nn.pytorch.conv import SAGEConv \n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 9강 정리 \n",
    "---\n",
    "1. 정점 표현 학습 \n",
    "- 그래프의 정점들을 벡터로 표현하는 것 \n",
    "- 그래프에서 정점 사이의 유사성을 계산하는 방법에 따라 여러 접근법이 구분됨\n",
    "- 그래프 신경망 등의 귀납식 정점 표현 학습은 임베딩 함수를 출력으로 얻음 \n",
    "2. 그래프 신경망 기본 \n",
    "- 그래프 신경망은 이웃 정점들의 정보를 집계하는 과정을 반복하여 임베딩을 얻음 \n",
    "- 후속 과제의 손실함수를 사용해 종단종 학습이 가능함\n",
    "- 학습된 그래프 신경망을 학습에서 제외한 정점, 새롭게 추가된 정점, 새로운 그래프에 적용 가능 \n",
    "3. 그래프 신경망 변형 \n",
    "4. 합성곱 신경망과의 비교\n",
    "- 그래프 형태의 데이터에서는 합성곱 신경망이 아닌 그래프 신경망을 사용해야 효과적 \n",
    "5. 실습 : DGL 라이브러이와 GraphSAGE를 이용한 정점 분류 \n"
   ]
  }
 ]
}